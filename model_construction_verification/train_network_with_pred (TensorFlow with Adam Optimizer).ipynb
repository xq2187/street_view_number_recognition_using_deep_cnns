{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import os\n",
    "import tarfile\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "# import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageOps\n",
    "import pandas as pd\n",
    "import csv\n",
    "from numpy import savez_compressed\n",
    "from numpy import load\n",
    "import glob\n",
    "from skimage.util import img_as_ubyte\n",
    "import train_with_pred\n",
    "import tensorflow as tf\n",
    "from tempfile import TemporaryFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = load(os.getcwd()+'/data/final_train_image_cropped.npz', allow_pickle=True)\n",
    "train = train_data1['arr_0']\n",
    "\n",
    "val_data1 = load(os.getcwd()+'/data/final_validation_image_cropped.npz', allow_pickle=True)\n",
    "val = val_data1['arr_0']\n",
    "\n",
    "val_data = load(os.getcwd()+'/data/final_validation_label.npz', allow_pickle=True)\n",
    "val_label = val_data['arr_0']\n",
    "\n",
    "train_data = load(os.getcwd()+'/data/final_train_label.npz', allow_pickle=True)\n",
    "train_label = train_data['arr_0']\n",
    "\n",
    "test_data1 = load(os.getcwd()+'/data/final_test_image_cropped.npz', allow_pickle=True)\n",
    "test = test_data1['arr_0']\n",
    "\n",
    "test_data = load(os.getcwd()+'/data/final_test_label.npz', allow_pickle=True)\n",
    "test_label = test_data['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ecbm4040/Final_Project/My_cnn.py:58: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /home/ecbm4040/Final_Project/My_cnn.py:63: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/ecbm4040/Final_Project/My_cnn.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "number of batches for training: 26\n",
      "WARNING:tensorflow:From /home/ecbm4040/miniconda3/envs/envTF113/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "epoch 1 \n",
      "7.1815515\n",
      "0.0\n",
      "epoch 2 \n",
      "6.929515\n",
      "0.0016467066\n",
      "Best validation accuracy! iteration:40 accuracy: 0.0016467066016048193\n",
      "prediction:  0.0015968063\n",
      "epoch 3 \n",
      "6.731906\n",
      "0.0013473054\n",
      "epoch 4 \n",
      "6.5761847\n",
      "0.0025748503\n",
      "Best validation accuracy! iteration:80 accuracy: 0.0025748503394424915\n",
      "prediction:  0.0030439121\n",
      "6.12177\n",
      "0.005902481\n",
      "Best validation accuracy! iteration:100 accuracy: 0.00590248079970479\n",
      "prediction:  0.007447605\n",
      "epoch 5 \n",
      "5.859278\n",
      "0.009913506\n",
      "Best validation accuracy! iteration:120 accuracy: 0.009913505986332893\n",
      "prediction:  0.011377245\n",
      "epoch 6 \n",
      "5.779609\n",
      "0.015459989\n",
      "Best validation accuracy! iteration:140 accuracy: 0.015459989197552204\n",
      "prediction:  0.018188622\n",
      "epoch 7 \n",
      "5.1418304\n",
      "0.023652695\n",
      "Best validation accuracy! iteration:160 accuracy: 0.02365269511938095\n",
      "prediction:  0.027630454\n",
      "5.163559\n",
      "0.031417165\n",
      "Best validation accuracy! iteration:180 accuracy: 0.03141716495156288\n",
      "prediction:  0.034393713\n",
      "epoch 8 \n",
      "4.389406\n",
      "0.041704826\n",
      "Best validation accuracy! iteration:200 accuracy: 0.041704826056957245\n",
      "prediction:  0.048070524\n",
      "epoch 9 \n",
      "3.9158037\n",
      "0.05595651\n",
      "Best validation accuracy! iteration:220 accuracy: 0.055956508964300156\n",
      "prediction:  0.06390718\n",
      "epoch 10 \n",
      "3.92582\n",
      "0.07231252\n",
      "Best validation accuracy! iteration:240 accuracy: 0.07231251895427704\n",
      "prediction:  0.08079749\n",
      "3.33807\n",
      "0.09203333\n",
      "Best validation accuracy! iteration:260 accuracy: 0.09203332662582397\n",
      "prediction:  0.10249501\n",
      "epoch 11 \n",
      "2.8834722\n",
      "0.11401197\n",
      "Best validation accuracy! iteration:280 accuracy: 0.1140119731426239\n",
      "prediction:  0.12524183\n",
      "epoch 12 \n",
      "2.6357977\n",
      "0.13784653\n",
      "Best validation accuracy! iteration:300 accuracy: 0.13784652948379517\n",
      "prediction:  0.15004277\n",
      "epoch 13 \n",
      "2.0621343\n",
      "0.16237868\n",
      "Best validation accuracy! iteration:320 accuracy: 0.1623786836862564\n",
      "prediction:  0.17376247\n",
      "epoch 14 \n",
      "2.0515475\n",
      "0.18558045\n",
      "Best validation accuracy! iteration:340 accuracy: 0.18558044731616974\n",
      "prediction:  0.19700599\n",
      "1.8379836\n",
      "0.2080929\n",
      "Best validation accuracy! iteration:360 accuracy: 0.20809289813041687\n",
      "prediction:  0.2184572\n",
      "epoch 15 \n",
      "1.7984502\n",
      "0.22877674\n",
      "Best validation accuracy! iteration:380 accuracy: 0.2287767380475998\n",
      "prediction:  0.23872255\n",
      "epoch 16 \n",
      "1.6239355\n",
      "0.2487053\n",
      "Best validation accuracy! iteration:400 accuracy: 0.24870529770851135\n",
      "prediction:  0.25784746\n",
      "epoch 17 \n",
      "1.4690071\n",
      "0.26628283\n",
      "Best validation accuracy! iteration:420 accuracy: 0.2662828266620636\n",
      "prediction:  0.27430388\n",
      "1.4710165\n",
      "0.28250328\n",
      "Best validation accuracy! iteration:440 accuracy: 0.28250327706336975\n",
      "prediction:  0.29014114\n",
      "epoch 18 \n",
      "1.2596416\n",
      "0.29761872\n",
      "Best validation accuracy! iteration:460 accuracy: 0.29761871695518494\n",
      "prediction:  0.30480403\n",
      "epoch 19 \n",
      "1.519381\n",
      "0.3121091\n",
      "Best validation accuracy! iteration:480 accuracy: 0.312109112739563\n",
      "prediction:  0.3191812\n",
      "epoch 20 \n",
      "1.1913154\n",
      "0.32608613\n",
      "Best validation accuracy! iteration:500 accuracy: 0.3260861337184906\n",
      "prediction:  0.33291543\n",
      "1.3057598\n",
      "0.3391299\n",
      "Best validation accuracy! iteration:520 accuracy: 0.33912989497184753\n",
      "prediction:  0.34546107\n",
      "epoch 21 \n",
      "1.1239043\n",
      "0.3509217\n",
      "Best validation accuracy! iteration:540 accuracy: 0.3509216904640198\n",
      "prediction:  0.35617226\n",
      "epoch 22 \n",
      "1.1264126\n",
      "0.3613829\n",
      "Best validation accuracy! iteration:560 accuracy: 0.3613829016685486\n",
      "prediction:  0.3663229\n",
      "epoch 23 \n",
      "0.8957898\n",
      "0.37139902\n",
      "Best validation accuracy! iteration:580 accuracy: 0.37139901518821716\n",
      "prediction:  0.37636334\n",
      "epoch 24 \n",
      "0.9240609\n",
      "0.38081732\n",
      "Best validation accuracy! iteration:600 accuracy: 0.38081732392311096\n",
      "prediction:  0.38527256\n",
      "0.72326005\n",
      "0.38954633\n",
      "Best validation accuracy! iteration:620 accuracy: 0.38954633474349976\n",
      "prediction:  0.3937026\n",
      "epoch 25 \n",
      "0.80538666\n",
      "0.39777657\n",
      "Best validation accuracy! iteration:640 accuracy: 0.3977765738964081\n",
      "prediction:  0.40174812\n",
      "epoch 26 \n",
      "0.65928906\n",
      "0.40578842\n",
      "Best validation accuracy! iteration:660 accuracy: 0.4057884216308594\n",
      "prediction:  0.40994573\n",
      "epoch 27 \n",
      "0.6157513\n",
      "0.41374943\n",
      "Best validation accuracy! iteration:680 accuracy: 0.41374942660331726\n",
      "prediction:  0.41751042\n",
      "0.60057503\n",
      "0.42106533\n",
      "Best validation accuracy! iteration:700 accuracy: 0.4210653305053711\n",
      "prediction:  0.42452008\n",
      "epoch 28 \n",
      "0.5480594\n",
      "0.42782262\n",
      "Best validation accuracy! iteration:720 accuracy: 0.42782261967658997\n",
      "prediction:  0.43119332\n",
      "epoch 29 \n",
      "0.5402557\n",
      "0.43428355\n",
      "Best validation accuracy! iteration:740 accuracy: 0.4342835545539856\n",
      "prediction:  0.4372713\n",
      "epoch 30 \n",
      "0.5122582\n",
      "0.44031662\n",
      "Best validation accuracy! iteration:760 accuracy: 0.4403166174888611\n",
      "prediction:  0.4432392\n",
      "0.47010264\n",
      "0.4462036\n",
      "Best validation accuracy! iteration:780 accuracy: 0.4462035894393921\n",
      "prediction:  0.4491018\n",
      "epoch 31 \n",
      "0.48417795\n",
      "0.45168364\n",
      "Best validation accuracy! iteration:800 accuracy: 0.4516836404800415\n",
      "prediction:  0.4542492\n",
      "epoch 32 \n",
      "0.48651093\n",
      "0.456818\n",
      "Best validation accuracy! iteration:820 accuracy: 0.45681801438331604\n",
      "prediction:  0.45940495\n",
      "epoch 33 \n",
      "0.537485\n",
      "0.46188733\n",
      "Best validation accuracy! iteration:840 accuracy: 0.46188732981681824\n",
      "prediction:  0.4643749\n",
      "epoch 34 \n",
      "0.57039315\n",
      "0.46662578\n",
      "Best validation accuracy! iteration:860 accuracy: 0.46662577986717224\n",
      "prediction:  0.46888366\n",
      "0.424037\n",
      "0.47113067\n",
      "Best validation accuracy! iteration:880 accuracy: 0.4711306691169739\n",
      "prediction:  0.4735204\n",
      "epoch 35 \n",
      "0.42919743\n",
      "0.4756005\n",
      "Best validation accuracy! iteration:900 accuracy: 0.4756005108356476\n",
      "prediction:  0.47773203\n",
      "epoch 36 \n",
      "0.45612812\n",
      "0.47973827\n",
      "Best validation accuracy! iteration:920 accuracy: 0.4797382652759552\n",
      "prediction:  0.48179972\n",
      "epoch 37 \n",
      "0.47855988\n",
      "0.48383233\n",
      "Best validation accuracy! iteration:940 accuracy: 0.48383232951164246\n",
      "prediction:  0.48585328\n",
      "0.48781097\n",
      "0.48763764\n",
      "Best validation accuracy! iteration:960 accuracy: 0.48763763904571533\n",
      "prediction:  0.48956874\n",
      "epoch 38 \n",
      "0.26587316\n",
      "0.49148124\n",
      "Best validation accuracy! iteration:980 accuracy: 0.4914812445640564\n",
      "prediction:  0.49345684\n",
      "epoch 39 \n",
      "0.20826139\n",
      "0.49537626\n",
      "Best validation accuracy! iteration:1000 accuracy: 0.49537625908851624\n",
      "prediction:  0.4973054\n",
      "epoch 40 \n",
      "0.18362154\n",
      "0.49902317\n",
      "Best validation accuracy! iteration:1020 accuracy: 0.4990231692790985\n",
      "prediction:  0.50074553\n",
      "0.11877233\n",
      "0.5024782\n",
      "Best validation accuracy! iteration:1040 accuracy: 0.5024781823158264\n",
      "prediction:  0.5042239\n",
      "epoch 41 \n",
      "0.18251681\n",
      "0.50588626\n",
      "Best validation accuracy! iteration:1060 accuracy: 0.5058862566947937\n",
      "prediction:  0.50771534\n",
      "epoch 42 \n",
      "0.14554994\n",
      "0.5092871\n",
      "Best validation accuracy! iteration:1080 accuracy: 0.5092871189117432\n",
      "prediction:  0.5108971\n",
      "epoch 43 \n",
      "0.2755064\n",
      "0.5124769\n",
      "Best validation accuracy! iteration:1100 accuracy: 0.512476921081543\n",
      "prediction:  0.5141107\n",
      "epoch 44 \n",
      "0.24342056\n",
      "0.5156293\n",
      "Best validation accuracy! iteration:1120 accuracy: 0.5156292915344238\n",
      "prediction:  0.5171502\n",
      "0.0846827\n",
      "0.5186033\n",
      "Best validation accuracy! iteration:1140 accuracy: 0.5186033248901367\n",
      "prediction:  0.52011603\n",
      "epoch 45 \n",
      "0.111536145\n",
      "0.521488\n",
      "Best validation accuracy! iteration:1160 accuracy: 0.5214880108833313\n",
      "prediction:  0.5228648\n",
      "epoch 46 \n",
      "0.13098307\n",
      "0.5240666\n",
      "Best validation accuracy! iteration:1180 accuracy: 0.5240666270256042\n",
      "prediction:  0.5252762\n",
      "epoch 47 \n",
      "0.09144974\n",
      "0.5265213\n",
      "Best validation accuracy! iteration:1200 accuracy: 0.5265213251113892\n",
      "prediction:  0.52786463\n",
      "0.18142007\n",
      "0.52916014\n",
      "Best validation accuracy! iteration:1220 accuracy: 0.5291601419448853\n",
      "prediction:  0.5304541\n",
      "epoch 48 \n",
      "0.2425332\n",
      "0.53154105\n",
      "Best validation accuracy! iteration:1240 accuracy: 0.5315410494804382\n",
      "prediction:  0.53268874\n",
      "epoch 49 \n",
      "0.13524538\n",
      "0.53386885\n",
      "Best validation accuracy! iteration:1260 accuracy: 0.5338688492774963\n",
      "prediction:  0.53508306\n",
      "epoch 50 \n",
      "0.17215444\n",
      "0.5361485\n",
      "Best validation accuracy! iteration:1280 accuracy: 0.5361484885215759\n",
      "prediction:  0.537159\n",
      "0.22229707\n",
      "0.5383092\n",
      "Best validation accuracy! iteration:1300 accuracy: 0.5383092164993286\n",
      "prediction:  0.5395397\n",
      "epoch 51 \n",
      "0.10500041\n",
      "0.54058397\n",
      "Best validation accuracy! iteration:1320 accuracy: 0.5405839681625366\n",
      "prediction:  0.54169506\n",
      "epoch 52 \n",
      "0.11233068\n",
      "0.54278237\n",
      "Best validation accuracy! iteration:1340 accuracy: 0.5427823662757874\n",
      "prediction:  0.5439417\n",
      "epoch 53 \n",
      "0.09591055\n",
      "0.5449687\n",
      "Best validation accuracy! iteration:1360 accuracy: 0.5449687242507935\n",
      "prediction:  0.546043\n",
      "epoch 54 \n",
      "0.089081466\n",
      "0.54713017\n",
      "Best validation accuracy! iteration:1380 accuracy: 0.5471301674842834\n",
      "prediction:  0.54822344\n",
      "0.04887643\n",
      "0.5492591\n",
      "Best validation accuracy! iteration:1400 accuracy: 0.5492591261863708\n",
      "prediction:  0.55030376\n",
      "epoch 55 \n",
      "0.07078425\n",
      "0.5512515\n",
      "Best validation accuracy! iteration:1420 accuracy: 0.5512514710426331\n",
      "prediction:  0.5521835\n",
      "epoch 56 \n",
      "0.13312972\n",
      "0.5530428\n",
      "Best validation accuracy! iteration:1440 accuracy: 0.5530428290367126\n",
      "prediction:  0.5539491\n",
      "epoch 57 \n",
      "0.07615044\n",
      "0.55488676\n",
      "Best validation accuracy! iteration:1460 accuracy: 0.5548867583274841\n",
      "prediction:  0.55586535\n",
      "0.0455076\n",
      "0.5566942\n",
      "Best validation accuracy! iteration:1480 accuracy: 0.5566942095756531\n",
      "prediction:  0.55760604\n",
      "epoch 58 \n",
      "0.057831388\n",
      "0.5584708\n",
      "Best validation accuracy! iteration:1500 accuracy: 0.5584707856178284\n",
      "prediction:  0.55939066\n",
      "epoch 59 \n",
      "0.05408211\n",
      "0.5602982\n",
      "Best validation accuracy! iteration:1520 accuracy: 0.5602982044219971\n",
      "prediction:  0.5611976\n",
      "epoch 60 \n",
      "0.0733285\n",
      "0.56208116\n",
      "Best validation accuracy! iteration:1540 accuracy: 0.5620811581611633\n",
      "prediction:  0.5629727\n",
      "0.051134344\n",
      "0.56375873\n",
      "Best validation accuracy! iteration:1560 accuracy: 0.5637587308883667\n",
      "prediction:  0.5646026\n",
      "epoch 61 \n",
      "0.052626353\n",
      "0.5653487\n",
      "Best validation accuracy! iteration:1580 accuracy: 0.5653486847877502\n",
      "prediction:  0.5662387\n",
      "epoch 62 \n",
      "0.0454501\n",
      "0.56700677\n",
      "Best validation accuracy! iteration:1600 accuracy: 0.5670067667961121\n",
      "prediction:  0.5677329\n",
      "epoch 63 \n",
      "0.06242991\n",
      "0.56848\n",
      "Best validation accuracy! iteration:1620 accuracy: 0.5684800148010254\n",
      "prediction:  0.5692646\n",
      "epoch 64 \n",
      "0.06842859\n",
      "0.5700078\n",
      "Best validation accuracy! iteration:1640 accuracy: 0.5700078010559082\n",
      "prediction:  0.5707899\n",
      "0.056647714\n",
      "0.5715312\n",
      "Best validation accuracy! iteration:1660 accuracy: 0.5715311765670776\n",
      "prediction:  0.5723273\n",
      "epoch 65 \n",
      "0.05549578\n",
      "0.57309383\n",
      "Best validation accuracy! iteration:1680 accuracy: 0.573093831539154\n",
      "prediction:  0.5738601\n",
      "epoch 66 \n",
      "0.036252\n",
      "0.5745419\n",
      "Best validation accuracy! iteration:1700 accuracy: 0.5745419263839722\n",
      "prediction:  0.5752727\n",
      "epoch 67 \n",
      "0.04079249\n",
      "0.57591856\n",
      "Best validation accuracy! iteration:1720 accuracy: 0.5759185552597046\n",
      "prediction:  0.57661325\n",
      "0.05059006\n",
      "0.5772402\n",
      "Best validation accuracy! iteration:1740 accuracy: 0.5772402286529541\n",
      "prediction:  0.57796097\n",
      "epoch 68 \n",
      "0.037658848\n",
      "0.5786283\n",
      "Best validation accuracy! iteration:1760 accuracy: 0.5786283016204834\n",
      "prediction:  0.5793275\n",
      "epoch 69 \n",
      "0.03887357\n",
      "0.58\n",
      "Best validation accuracy! iteration:1780 accuracy: 0.5799999833106995\n",
      "prediction:  0.58069885\n",
      "epoch 70 \n",
      "0.057009894\n",
      "0.5813238\n",
      "Best validation accuracy! iteration:1800 accuracy: 0.5813238024711609\n",
      "prediction:  0.58199894\n",
      "0.030947836\n",
      "0.582628\n",
      "Best validation accuracy! iteration:1820 accuracy: 0.5826280117034912\n",
      "prediction:  0.5832901\n",
      "epoch 71 \n",
      "0.100457676\n",
      "0.58389187\n",
      "Best validation accuracy! iteration:1840 accuracy: 0.5838918685913086\n",
      "prediction:  0.5845249\n",
      "epoch 72 \n",
      "0.04509675\n",
      "0.58507085\n",
      "Best validation accuracy! iteration:1860 accuracy: 0.5850708484649658\n",
      "prediction:  0.5856645\n",
      "epoch 73 \n",
      "0.08057548\n",
      "0.5862178\n",
      "Best validation accuracy! iteration:1880 accuracy: 0.5862178206443787\n",
      "prediction:  0.5867732\n",
      "epoch 74 \n",
      "0.07756015\n",
      "0.58730507\n",
      "Best validation accuracy! iteration:1900 accuracy: 0.5873050689697266\n",
      "prediction:  0.58792204\n",
      "0.03977869\n",
      "0.5884501\n",
      "Best validation accuracy! iteration:1920 accuracy: 0.5884500741958618\n",
      "prediction:  0.58900726\n",
      "epoch 75 \n",
      "0.044432864\n",
      "0.5895194\n",
      "Best validation accuracy! iteration:1940 accuracy: 0.5895193815231323\n",
      "prediction:  0.5900418\n",
      "epoch 76 \n",
      "0.06995977\n",
      "0.5905324\n",
      "Best validation accuracy! iteration:1960 accuracy: 0.5905324220657349\n",
      "prediction:  0.59104264\n",
      "epoch 77 \n",
      "0.039592445\n",
      "0.59159374\n",
      "Best validation accuracy! iteration:1980 accuracy: 0.5915937423706055\n",
      "prediction:  0.5921438\n",
      "0.06518213\n",
      "0.5926411\n",
      "Best validation accuracy! iteration:2000 accuracy: 0.5926411151885986\n",
      "prediction:  0.59313947\n",
      "epoch 78 \n",
      "0.06881245\n",
      "0.5935937\n",
      "Best validation accuracy! iteration:2020 accuracy: 0.5935937166213989\n",
      "prediction:  0.59408236\n",
      "epoch 79 \n",
      "0.07953769\n",
      "0.59458697\n",
      "Best validation accuracy! iteration:2040 accuracy: 0.594586968421936\n",
      "prediction:  0.5951177\n",
      "epoch 80 \n",
      "0.030285705\n",
      "0.5955857\n",
      "Best validation accuracy! iteration:2060 accuracy: 0.5955857038497925\n",
      "prediction:  0.5960814\n",
      "0.03996793\n",
      "0.59656054\n",
      "Best validation accuracy! iteration:2080 accuracy: 0.596560537815094\n",
      "prediction:  0.59710044\n",
      "epoch 81 \n",
      "0.072181016\n",
      "0.5974703\n",
      "Best validation accuracy! iteration:2100 accuracy: 0.5974702835083008\n",
      "prediction:  0.5978927\n",
      "epoch 82 \n",
      "0.046379298\n",
      "0.5983497\n",
      "Best validation accuracy! iteration:2120 accuracy: 0.5983496904373169\n",
      "prediction:  0.5988452\n",
      "epoch 83 \n",
      "0.07191848\n",
      "0.59924936\n",
      "Best validation accuracy! iteration:2140 accuracy: 0.5992493629455566\n",
      "prediction:  0.5997161\n",
      "epoch 84 \n",
      "0.089003816\n",
      "0.60016584\n",
      "Best validation accuracy! iteration:2160 accuracy: 0.600165843963623\n",
      "prediction:  0.600666\n",
      "0.026855826\n",
      "0.6010987\n",
      "Best validation accuracy! iteration:2180 accuracy: 0.6010987162590027\n",
      "prediction:  0.6015317\n",
      "epoch 85 \n",
      "0.07400445\n",
      "0.6019399\n",
      "Best validation accuracy! iteration:2200 accuracy: 0.6019399166107178\n",
      "prediction:  0.6024117\n",
      "epoch 86 \n",
      "0.04000155\n",
      "0.60289013\n",
      "Best validation accuracy! iteration:2220 accuracy: 0.602890133857727\n",
      "prediction:  0.6033778\n",
      "epoch 87 \n",
      "0.031315427\n",
      "0.6037608\n",
      "Best validation accuracy! iteration:2240 accuracy: 0.6037607789039612\n",
      "prediction:  0.60422534\n",
      "0.05284212\n",
      "0.6046226\n",
      "Best validation accuracy! iteration:2260 accuracy: 0.6046226024627686\n",
      "prediction:  0.6050778\n",
      "epoch 88 \n",
      "0.054486465\n",
      "0.6054917\n",
      "Best validation accuracy! iteration:2280 accuracy: 0.6054916977882385\n",
      "prediction:  0.6059496\n",
      "epoch 89 \n",
      "0.075339936\n",
      "0.6063468\n",
      "Best validation accuracy! iteration:2300 accuracy: 0.6063467860221863\n",
      "prediction:  0.606793\n",
      "epoch 90 \n",
      "0.084936395\n",
      "0.6071425\n",
      "Best validation accuracy! iteration:2320 accuracy: 0.6071425080299377\n",
      "prediction:  0.60752666\n",
      "0.06341742\n",
      "0.6078894\n",
      "Best validation accuracy! iteration:2340 accuracy: 0.6078894138336182\n",
      "prediction:  0.6082645\n",
      "epoch 91 \n",
      "0.09252759\n",
      "0.60865563\n",
      "Best validation accuracy! iteration:2360 accuracy: 0.6086556315422058\n",
      "prediction:  0.60902554\n",
      "epoch 92 \n",
      "0.097071275\n",
      "0.6094279\n",
      "Best validation accuracy! iteration:2380 accuracy: 0.6094279289245605\n",
      "prediction:  0.6097851\n",
      "epoch 93 \n",
      "0.12123742\n",
      "0.61010766\n",
      "Best validation accuracy! iteration:2400 accuracy: 0.6101076602935791\n",
      "prediction:  0.6104413\n",
      "epoch 94 \n",
      "0.079327926\n",
      "0.61077845\n",
      "Best validation accuracy! iteration:2420 accuracy: 0.6107784509658813\n",
      "prediction:  0.6111752\n",
      "0.044759158\n",
      "0.6115561\n",
      "Best validation accuracy! iteration:2440 accuracy: 0.6115561127662659\n",
      "prediction:  0.611934\n",
      "epoch 95 \n",
      "0.06519721\n",
      "0.61228037\n",
      "Best validation accuracy! iteration:2460 accuracy: 0.6122803688049316\n",
      "prediction:  0.61263496\n",
      "epoch 96 \n",
      "0.049835052\n",
      "0.61296225\n",
      "Best validation accuracy! iteration:2480 accuracy: 0.6129622459411621\n",
      "prediction:  0.6133124\n",
      "epoch 97 \n",
      "0.026844388\n",
      "0.61360276\n",
      "Best validation accuracy! iteration:2500 accuracy: 0.6136027574539185\n",
      "prediction:  0.61393183\n",
      "0.035341084\n",
      "0.61426544\n",
      "Best validation accuracy! iteration:2520 accuracy: 0.6142654418945312\n",
      "prediction:  0.6146024\n",
      "epoch 98 \n",
      "0.051711984\n",
      "0.6149414\n",
      "Best validation accuracy! iteration:2540 accuracy: 0.614941418170929\n",
      "prediction:  0.6153063\n",
      "epoch 99 \n",
      "0.054998834\n",
      "0.6156316\n",
      "Best validation accuracy! iteration:2560 accuracy: 0.6156315803527832\n",
      "prediction:  0.6160003\n",
      "epoch 100 \n",
      "0.062241457\n",
      "0.6163121\n",
      "Best validation accuracy! iteration:2580 accuracy: 0.6163120865821838\n",
      "prediction:  0.6166343\n",
      "0.047044877\n",
      "0.6169412\n",
      "Best validation accuracy! iteration:2600 accuracy: 0.6169412136077881\n",
      "prediction:  0.61727476\n",
      "epoch 101 \n",
      "0.07485294\n",
      "0.6176057\n",
      "Best validation accuracy! iteration:2620 accuracy: 0.6176056861877441\n",
      "prediction:  0.6179088\n",
      "epoch 102 \n",
      "0.032805018\n",
      "0.61821073\n",
      "Best validation accuracy! iteration:2640 accuracy: 0.6182107329368591\n",
      "prediction:  0.6185412\n",
      "epoch 103 \n",
      "0.051407244\n",
      "0.61886567\n",
      "Best validation accuracy! iteration:2660 accuracy: 0.6188656687736511\n",
      "prediction:  0.6192036\n",
      "epoch 104 \n",
      "0.084478065\n",
      "0.6195266\n",
      "Best validation accuracy! iteration:2680 accuracy: 0.6195266246795654\n",
      "prediction:  0.6198528\n",
      "0.03153817\n",
      "0.6201653\n",
      "Best validation accuracy! iteration:2700 accuracy: 0.6201652884483337\n",
      "prediction:  0.62047994\n",
      "epoch 105 \n",
      "0.03558784\n",
      "0.6207544\n",
      "Best validation accuracy! iteration:2720 accuracy: 0.6207544207572937\n",
      "prediction:  0.6210446\n",
      "epoch 106 \n",
      "0.09917148\n",
      "0.6213006\n",
      "Best validation accuracy! iteration:2740 accuracy: 0.6213005781173706\n",
      "prediction:  0.62155026\n",
      "epoch 107 \n",
      "0.033640992\n",
      "0.621842\n",
      "Best validation accuracy! iteration:2760 accuracy: 0.6218420267105103\n",
      "prediction:  0.62209666\n",
      "0.07019402\n",
      "0.6223462\n",
      "Best validation accuracy! iteration:2780 accuracy: 0.6223462224006653\n",
      "prediction:  0.6226319\n",
      "epoch 108 \n",
      "0.09190546\n",
      "0.62287986\n",
      "Best validation accuracy! iteration:2800 accuracy: 0.6228798627853394\n",
      "prediction:  0.6231142\n",
      "epoch 109 \n",
      "0.084854774\n",
      "0.6233898\n",
      "Best validation accuracy! iteration:2820 accuracy: 0.6233897805213928\n",
      "prediction:  0.62367195\n",
      "epoch 110 \n",
      "0.05088454\n",
      "0.6239649\n",
      "Best validation accuracy! iteration:2840 accuracy: 0.6239649057388306\n",
      "prediction:  0.6242387\n",
      "0.10598618\n",
      "0.6244758\n",
      "Best validation accuracy! iteration:2860 accuracy: 0.6244757771492004\n",
      "prediction:  0.6247354\n",
      "epoch 111 \n",
      "0.025053805\n",
      "0.62496793\n",
      "Best validation accuracy! iteration:2880 accuracy: 0.6249679327011108\n",
      "prediction:  0.6252104\n",
      "epoch 112 \n",
      "0.037909154\n",
      "0.6254804\n",
      "Best validation accuracy! iteration:2900 accuracy: 0.6254804134368896\n",
      "prediction:  0.6257329\n",
      "epoch 113 \n",
      "0.06564082\n",
      "0.6259702\n",
      "Best validation accuracy! iteration:2920 accuracy: 0.625970184803009\n",
      "prediction:  0.62617487\n",
      "epoch 114 \n",
      "0.038975235\n",
      "0.6264111\n",
      "Best validation accuracy! iteration:2940 accuracy: 0.6264110803604126\n",
      "prediction:  0.6266293\n",
      "0.06046431\n",
      "0.6268541\n",
      "Best validation accuracy! iteration:2960 accuracy: 0.6268541216850281\n",
      "prediction:  0.6270744\n",
      "epoch 115 \n",
      "0.049575303\n",
      "0.62731045\n",
      "Best validation accuracy! iteration:2980 accuracy: 0.6273104548454285\n",
      "prediction:  0.62754893\n",
      "epoch 116 \n",
      "0.09698582\n",
      "0.62778586\n",
      "Best validation accuracy! iteration:3000 accuracy: 0.627785861492157\n",
      "prediction:  0.62804425\n",
      "epoch 117 \n",
      "0.03921432\n",
      "0.6282759\n",
      "Best validation accuracy! iteration:3020 accuracy: 0.6282758712768555\n",
      "prediction:  0.62852794\n",
      "0.12004716\n",
      "0.62877136\n",
      "Best validation accuracy! iteration:3040 accuracy: 0.6287713646888733\n",
      "prediction:  0.6290181\n",
      "epoch 118 \n",
      "0.061271094\n",
      "0.6292534\n",
      "Best validation accuracy! iteration:3060 accuracy: 0.6292533874511719\n",
      "prediction:  0.62952054\n",
      "epoch 119 \n",
      "0.08085067\n",
      "0.62974477\n",
      "Best validation accuracy! iteration:3080 accuracy: 0.6297447681427002\n",
      "prediction:  0.6299724\n",
      "epoch 120 \n",
      "0.06905667\n",
      "0.63020444\n",
      "Best validation accuracy! iteration:3100 accuracy: 0.630204439163208\n",
      "prediction:  0.6304203\n",
      "0.021755148\n",
      "0.6306155\n",
      "Best validation accuracy! iteration:3120 accuracy: 0.6306154727935791\n",
      "prediction:  0.6308287\n",
      "epoch 121 \n",
      "0.055088513\n",
      "0.6310463\n",
      "Best validation accuracy! iteration:3140 accuracy: 0.6310462951660156\n",
      "prediction:  0.6312414\n",
      "epoch 122 \n",
      "0.054205086\n",
      "0.631461\n",
      "Best validation accuracy! iteration:3160 accuracy: 0.6314610242843628\n",
      "prediction:  0.63169456\n",
      "epoch 123 \n",
      "0.04998873\n",
      "0.63189906\n",
      "Best validation accuracy! iteration:3180 accuracy: 0.6318990588188171\n",
      "prediction:  0.63210416\n",
      "epoch 124 \n",
      "0.039903518\n",
      "0.6322928\n",
      "Best validation accuracy! iteration:3200 accuracy: 0.6322928071022034\n",
      "prediction:  0.63251513\n",
      "0.03414688\n",
      "0.6327408\n",
      "Best validation accuracy! iteration:3220 accuracy: 0.6327407956123352\n",
      "prediction:  0.6329407\n",
      "epoch 125 \n",
      "0.050389048\n",
      "0.6331599\n",
      "Best validation accuracy! iteration:3240 accuracy: 0.633159875869751\n",
      "prediction:  0.6333609\n",
      "epoch 126 \n",
      "0.042402856\n",
      "0.63355887\n",
      "Best validation accuracy! iteration:3260 accuracy: 0.6335588693618774\n",
      "prediction:  0.6337603\n",
      "epoch 127 \n",
      "0.04471624\n",
      "0.6339825\n",
      "Best validation accuracy! iteration:3280 accuracy: 0.6339824795722961\n",
      "prediction:  0.6341777\n",
      "0.034939297\n",
      "0.6343835\n",
      "Best validation accuracy! iteration:3300 accuracy: 0.634383499622345\n",
      "prediction:  0.6346\n",
      "epoch 128 \n",
      "0.037947487\n",
      "0.63479877\n",
      "Best validation accuracy! iteration:3320 accuracy: 0.6347987651824951\n",
      "prediction:  0.63499546\n",
      "epoch 129 \n",
      "0.03588667\n",
      "0.63521534\n",
      "Best validation accuracy! iteration:3340 accuracy: 0.6352153420448303\n",
      "prediction:  0.63541955\n",
      "epoch 130 \n",
      "0.047799412\n",
      "0.63564855\n",
      "Best validation accuracy! iteration:3360 accuracy: 0.6356485486030579\n",
      "prediction:  0.6358529\n",
      "0.042804457\n",
      "0.63605773\n",
      "Best validation accuracy! iteration:3380 accuracy: 0.6360577344894409\n",
      "prediction:  0.6362712\n",
      "epoch 131 \n",
      "0.020054385\n",
      "0.63647187\n",
      "Best validation accuracy! iteration:3400 accuracy: 0.6364718675613403\n",
      "prediction:  0.6366501\n",
      "epoch 132 \n",
      "0.04311499\n",
      "0.63684136\n",
      "Best validation accuracy! iteration:3420 accuracy: 0.636841356754303\n",
      "prediction:  0.63702536\n",
      "epoch 133 \n",
      "0.042861875\n",
      "0.63720655\n",
      "Best validation accuracy! iteration:3440 accuracy: 0.6372065544128418\n",
      "prediction:  0.63739276\n",
      "epoch 134 \n",
      "0.028644048\n",
      "0.6375997\n",
      "Best validation accuracy! iteration:3460 accuracy: 0.6375997066497803\n",
      "prediction:  0.6377855\n",
      "0.0150328465\n",
      "0.63799274\n",
      "Best validation accuracy! iteration:3480 accuracy: 0.6379927396774292\n",
      "prediction:  0.6382031\n",
      "epoch 135 \n",
      "0.10509861\n",
      "0.63837165\n",
      "Best validation accuracy! iteration:3500 accuracy: 0.6383716464042664\n",
      "prediction:  0.63855994\n",
      "epoch 136 \n",
      "0.0328475\n",
      "0.6387677\n",
      "Best validation accuracy! iteration:3520 accuracy: 0.6387677192687988\n",
      "prediction:  0.6389752\n",
      "epoch 137 \n",
      "0.042069517\n",
      "0.6391448\n",
      "Best validation accuracy! iteration:3540 accuracy: 0.639144778251648\n",
      "prediction:  0.6392862\n",
      "0.022376386\n",
      "0.6394777\n",
      "Best validation accuracy! iteration:3560 accuracy: 0.6394777297973633\n",
      "prediction:  0.6396436\n",
      "epoch 138 \n",
      "0.055153012\n",
      "0.63982034\n",
      "Best validation accuracy! iteration:3580 accuracy: 0.6398203372955322\n",
      "prediction:  0.64000624\n",
      "epoch 139 \n",
      "0.021789527\n",
      "0.6401994\n",
      "Best validation accuracy! iteration:3600 accuracy: 0.6401994228363037\n",
      "prediction:  0.64040244\n",
      "epoch 140 \n",
      "0.03587975\n",
      "0.64056426\n",
      "Best validation accuracy! iteration:3620 accuracy: 0.6405642628669739\n",
      "prediction:  0.6407352\n",
      "0.04376931\n",
      "0.6409267\n",
      "Best validation accuracy! iteration:3640 accuracy: 0.640926718711853\n",
      "prediction:  0.64112794\n",
      "epoch 141 \n",
      "0.07431148\n",
      "0.6413116\n",
      "Best validation accuracy! iteration:3660 accuracy: 0.6413115859031677\n",
      "prediction:  0.6414745\n",
      "epoch 142 \n",
      "0.026870722\n",
      "0.6416397\n",
      "Best validation accuracy! iteration:3680 accuracy: 0.6416397094726562\n",
      "prediction:  0.64181066\n",
      "epoch 143 \n",
      "0.016523965\n",
      "0.64198875\n",
      "Best validation accuracy! iteration:3700 accuracy: 0.6419887542724609\n",
      "prediction:  0.6421733\n",
      "epoch 144 \n",
      "0.038406186\n",
      "0.64236647\n",
      "Best validation accuracy! iteration:3720 accuracy: 0.6423664689064026\n",
      "prediction:  0.64253926\n",
      "0.0065864217\n",
      "0.6427232\n",
      "Best validation accuracy! iteration:3740 accuracy: 0.6427232027053833\n",
      "prediction:  0.6428868\n",
      "epoch 145 \n",
      "0.017556543\n",
      "0.643052\n",
      "Best validation accuracy! iteration:3760 accuracy: 0.6430519819259644\n",
      "prediction:  0.64322585\n",
      "epoch 146 \n",
      "0.023689562\n",
      "0.64336926\n",
      "Best validation accuracy! iteration:3780 accuracy: 0.6433692574501038\n",
      "prediction:  0.6435318\n",
      "epoch 147 \n",
      "0.037514918\n",
      "0.64373004\n",
      "Best validation accuracy! iteration:3800 accuracy: 0.6437300443649292\n",
      "prediction:  0.64391136\n",
      "0.025117561\n",
      "0.64407915\n",
      "Best validation accuracy! iteration:3820 accuracy: 0.6440791487693787\n",
      "prediction:  0.6442066\n",
      "epoch 148 \n",
      "0.028549556\n",
      "0.6443664\n",
      "Best validation accuracy! iteration:3840 accuracy: 0.6443663835525513\n",
      "prediction:  0.6445042\n",
      "epoch 149 \n",
      "0.044337824\n",
      "0.64470226\n",
      "Best validation accuracy! iteration:3860 accuracy: 0.6447022557258606\n",
      "prediction:  0.64486575\n",
      "epoch 150 \n",
      "0.09484212\n",
      "0.6450058\n",
      "Best validation accuracy! iteration:3880 accuracy: 0.6450058221817017\n",
      "prediction:  0.6451467\n",
      "0.025062716\n",
      "0.64531636\n",
      "Best validation accuracy! iteration:3900 accuracy: 0.6453163623809814\n",
      "prediction:  0.6454704\n",
      "epoch 151 \n",
      "0.07566456\n",
      "0.64560676\n",
      "Best validation accuracy! iteration:3920 accuracy: 0.6456067562103271\n",
      "prediction:  0.645727\n",
      "epoch 152 \n",
      "0.07714511\n",
      "0.6458612\n",
      "Best validation accuracy! iteration:3940 accuracy: 0.6458612084388733\n",
      "prediction:  0.64601004\n",
      "epoch 153 \n",
      "0.06918425\n",
      "0.64615804\n",
      "Best validation accuracy! iteration:3960 accuracy: 0.6461580395698547\n",
      "prediction:  0.6463099\n",
      "epoch 154 \n",
      "0.035572506\n",
      "0.6464443\n",
      "Best validation accuracy! iteration:3980 accuracy: 0.6464443206787109\n",
      "prediction:  0.64659166\n",
      "0.03477723\n",
      "0.64674205\n",
      "Best validation accuracy! iteration:4000 accuracy: 0.646742045879364\n",
      "prediction:  0.64690745\n",
      "epoch 155 \n",
      "0.06508061\n",
      "0.64705104\n",
      "Best validation accuracy! iteration:4020 accuracy: 0.6470510363578796\n",
      "prediction:  0.6472163\n",
      "epoch 156 \n",
      "0.023667296\n",
      "0.6473606\n",
      "Best validation accuracy! iteration:4040 accuracy: 0.647360622882843\n",
      "prediction:  0.647502\n",
      "epoch 157 \n",
      "0.056393508\n",
      "0.6476308\n",
      "Best validation accuracy! iteration:4060 accuracy: 0.6476308107376099\n",
      "prediction:  0.64777374\n",
      "0.04711127\n",
      "0.6479064\n",
      "Best validation accuracy! iteration:4080 accuracy: 0.6479064226150513\n",
      "prediction:  0.6480554\n",
      "epoch 158 \n",
      "0.020090766\n",
      "0.6481992\n",
      "Best validation accuracy! iteration:4100 accuracy: 0.648199200630188\n",
      "prediction:  0.64837676\n",
      "epoch 159 \n",
      "0.012231231\n",
      "0.64851177\n",
      "Best validation accuracy! iteration:4120 accuracy: 0.6485117673873901\n",
      "prediction:  0.64863884\n",
      "epoch 160 \n",
      "0.04215641\n",
      "0.6487682\n",
      "Best validation accuracy! iteration:4140 accuracy: 0.6487681865692139\n",
      "prediction:  0.6489099\n",
      "0.023041049\n",
      "0.64907134\n",
      "Best validation accuracy! iteration:4160 accuracy: 0.6490713357925415\n",
      "prediction:  0.6492327\n",
      "epoch 161 \n",
      "0.030895954\n",
      "0.6494005\n",
      "Best validation accuracy! iteration:4180 accuracy: 0.6494004726409912\n",
      "prediction:  0.6495552\n",
      "epoch 162 \n",
      "0.013393566\n",
      "0.6497114\n",
      "Best validation accuracy! iteration:4200 accuracy: 0.6497113704681396\n",
      "prediction:  0.64986676\n",
      "epoch 163 \n",
      "0.020885443\n",
      "0.6500064\n",
      "Best validation accuracy! iteration:4220 accuracy: 0.6500064134597778\n",
      "prediction:  0.65016466\n",
      "epoch 164 \n",
      "0.028200995\n",
      "0.65029585\n",
      "Best validation accuracy! iteration:4240 accuracy: 0.6502958536148071\n",
      "prediction:  0.65045905\n",
      "0.045722086\n",
      "0.6505896\n",
      "Best validation accuracy! iteration:4260 accuracy: 0.6505895853042603\n",
      "prediction:  0.6507238\n",
      "epoch 165 \n",
      "0.019679056\n",
      "0.650851\n",
      "Best validation accuracy! iteration:4280 accuracy: 0.6508510112762451\n",
      "prediction:  0.6509924\n",
      "epoch 166 \n",
      "0.031318624\n",
      "0.65111417\n",
      "Best validation accuracy! iteration:4300 accuracy: 0.6511141657829285\n",
      "prediction:  0.6512508\n",
      "epoch 167 \n",
      "0.040555134\n",
      "0.6513525\n",
      "Best validation accuracy! iteration:4320 accuracy: 0.6513525247573853\n",
      "prediction:  0.6514754\n",
      "0.05640696\n",
      "0.651604\n",
      "Best validation accuracy! iteration:4340 accuracy: 0.6516039967536926\n",
      "prediction:  0.6517257\n",
      "epoch 168 \n",
      "0.059614573\n",
      "0.6518358\n",
      "Best validation accuracy! iteration:4360 accuracy: 0.6518357992172241\n",
      "prediction:  0.65194815\n",
      "epoch 169 \n",
      "0.062190074\n",
      "0.6520731\n",
      "Best validation accuracy! iteration:4380 accuracy: 0.652073085308075\n",
      "prediction:  0.65218717\n",
      "epoch 170 \n",
      "0.048023984\n",
      "0.6523226\n",
      "Best validation accuracy! iteration:4400 accuracy: 0.6523225903511047\n",
      "prediction:  0.65243214\n",
      "0.016990796\n",
      "0.6525562\n",
      "Best validation accuracy! iteration:4420 accuracy: 0.6525561809539795\n",
      "prediction:  0.65267557\n",
      "epoch 171 \n",
      "0.026385728\n",
      "0.65278965\n",
      "Best validation accuracy! iteration:4440 accuracy: 0.6527896523475647\n",
      "prediction:  0.6528971\n",
      "epoch 172 \n",
      "0.055365294\n",
      "0.65299404\n",
      "Best validation accuracy! iteration:4460 accuracy: 0.6529940366744995\n",
      "prediction:  0.65311134\n",
      "epoch 173 \n",
      "0.10289924\n",
      "0.65318644\n",
      "Best validation accuracy! iteration:4480 accuracy: 0.6531864404678345\n",
      "prediction:  0.65329206\n",
      "epoch 174 \n",
      "0.061495505\n",
      "0.6533905\n",
      "Best validation accuracy! iteration:4500 accuracy: 0.6533905267715454\n",
      "prediction:  0.65347785\n",
      "0.034407638\n",
      "0.6535701\n",
      "Best validation accuracy! iteration:4520 accuracy: 0.6535701155662537\n",
      "prediction:  0.6536886\n",
      "epoch 175 \n",
      "0.07646442\n",
      "0.65377605\n",
      "Best validation accuracy! iteration:4540 accuracy: 0.6537760496139526\n",
      "prediction:  0.65387696\n",
      "epoch 176 \n",
      "0.036847956\n",
      "0.65397745\n",
      "Best validation accuracy! iteration:4560 accuracy: 0.6539774537086487\n",
      "prediction:  0.65409267\n",
      "epoch 177 \n",
      "0.04825859\n",
      "0.6542186\n",
      "Best validation accuracy! iteration:4580 accuracy: 0.6542186141014099\n",
      "prediction:  0.65436363\n",
      "0.173884\n",
      "0.6544687\n",
      "Best validation accuracy! iteration:4600 accuracy: 0.6544687151908875\n",
      "prediction:  0.65459365\n",
      "epoch 178 \n",
      "0.048342757\n",
      "0.6546991\n",
      "Best validation accuracy! iteration:4620 accuracy: 0.6546990871429443\n",
      "prediction:  0.65479887\n",
      "epoch 179 \n",
      "0.012672897\n",
      "0.6549086\n",
      "Best validation accuracy! iteration:4640 accuracy: 0.6549085974693298\n",
      "prediction:  0.65505093\n",
      "epoch 180 \n",
      "0.016490953\n",
      "0.6551629\n",
      "Best validation accuracy! iteration:4660 accuracy: 0.6551628708839417\n",
      "prediction:  0.65528536\n",
      "0.04127831\n",
      "0.65539825\n",
      "Best validation accuracy! iteration:4680 accuracy: 0.6553982496261597\n",
      "prediction:  0.6555209\n",
      "epoch 181 \n",
      "0.02826153\n",
      "0.655638\n",
      "Best validation accuracy! iteration:4700 accuracy: 0.6556379795074463\n",
      "prediction:  0.65575707\n",
      "epoch 182 \n",
      "0.028921887\n",
      "0.65586865\n",
      "Best validation accuracy! iteration:4720 accuracy: 0.655868649482727\n",
      "prediction:  0.6559842\n",
      "epoch 183 \n",
      "0.028222714\n",
      "0.65609354\n",
      "Best validation accuracy! iteration:4740 accuracy: 0.6560935378074646\n",
      "prediction:  0.65621763\n",
      "epoch 184 \n",
      "0.014324354\n",
      "0.65633553\n",
      "Best validation accuracy! iteration:4760 accuracy: 0.6563355326652527\n",
      "prediction:  0.65645546\n",
      "0.027703255\n",
      "0.6565717\n",
      "Best validation accuracy! iteration:4780 accuracy: 0.6565716862678528\n",
      "prediction:  0.6566931\n",
      "epoch 185 \n",
      "0.056306776\n",
      "0.65678144\n",
      "Best validation accuracy! iteration:4800 accuracy: 0.6567814350128174\n",
      "prediction:  0.6568875\n",
      "epoch 186 \n",
      "0.0390883\n",
      "0.6569875\n",
      "Best validation accuracy! iteration:4820 accuracy: 0.6569874882698059\n",
      "prediction:  0.6570977\n",
      "epoch 187 \n",
      "0.028574536\n",
      "0.6572105\n",
      "Best validation accuracy! iteration:4840 accuracy: 0.6572105288505554\n",
      "prediction:  0.65733844\n",
      "0.020625047\n",
      "0.6574497\n",
      "Best validation accuracy! iteration:4860 accuracy: 0.6574497222900391\n",
      "prediction:  0.6575605\n",
      "epoch 188 \n",
      "0.013329689\n",
      "0.65768445\n",
      "Best validation accuracy! iteration:4880 accuracy: 0.6576844453811646\n",
      "prediction:  0.6577986\n",
      "epoch 189 \n",
      "0.050476078\n",
      "0.6578797\n",
      "Best validation accuracy! iteration:4900 accuracy: 0.6578797101974487\n",
      "prediction:  0.65796787\n",
      "epoch 190 \n",
      "0.024159338\n",
      "0.65803975\n",
      "Best validation accuracy! iteration:4920 accuracy: 0.6580397486686707\n",
      "prediction:  0.65814185\n",
      "0.0442336\n",
      "0.6582302\n",
      "Best validation accuracy! iteration:4940 accuracy: 0.658230185508728\n",
      "prediction:  0.6583425\n",
      "epoch 191 \n",
      "0.05335819\n",
      "0.6584452\n",
      "Best validation accuracy! iteration:4960 accuracy: 0.6584451794624329\n",
      "prediction:  0.65853715\n",
      "epoch 192 \n",
      "0.02497784\n",
      "0.65863\n",
      "Best validation accuracy! iteration:4980 accuracy: 0.6586300134658813\n",
      "prediction:  0.65874845\n",
      "epoch 193 \n",
      "0.016737783\n",
      "0.65884346\n",
      "Best validation accuracy! iteration:5000 accuracy: 0.658843457698822\n",
      "prediction:  0.65895617\n",
      "epoch 194 \n",
      "0.024416257\n",
      "0.6590672\n",
      "Best validation accuracy! iteration:5020 accuracy: 0.6590672135353088\n",
      "prediction:  0.65918684\n",
      "0.038397297\n",
      "0.65927786\n",
      "Best validation accuracy! iteration:5040 accuracy: 0.6592778563499451\n",
      "prediction:  0.6593745\n",
      "epoch 195 \n",
      "0.010637191\n",
      "0.659482\n",
      "Best validation accuracy! iteration:5060 accuracy: 0.6594820022583008\n",
      "prediction:  0.6595874\n",
      "epoch 196 \n",
      "0.01595569\n",
      "0.6596876\n",
      "Best validation accuracy! iteration:5080 accuracy: 0.6596875786781311\n",
      "prediction:  0.6597773\n",
      "epoch 197 \n",
      "0.019360017\n",
      "0.6598743\n",
      "Best validation accuracy! iteration:5100 accuracy: 0.6598743200302124\n",
      "prediction:  0.659981\n",
      "0.020138076\n",
      "0.6600814\n",
      "Best validation accuracy! iteration:5120 accuracy: 0.6600813865661621\n",
      "prediction:  0.66018903\n",
      "epoch 198 \n",
      "0.0176626\n",
      "0.66029567\n",
      "Best validation accuracy! iteration:5140 accuracy: 0.6602956652641296\n",
      "prediction:  0.6603972\n",
      "epoch 199 \n",
      "0.029602973\n",
      "0.66049945\n",
      "Best validation accuracy! iteration:5160 accuracy: 0.6604994535446167\n",
      "prediction:  0.6606066\n",
      "epoch 200 \n",
      "0.037840102\n",
      "0.66069645\n",
      "Best validation accuracy! iteration:5180 accuracy: 0.6606964468955994\n",
      "prediction:  0.66079587\n",
      "0.036937132\n",
      "0.66087514\n",
      "Best validation accuracy! iteration:5200 accuracy: 0.660875141620636\n",
      "prediction:  0.6609709\n",
      "epoch 201 \n",
      "0.040064324\n",
      "0.6610559\n",
      "Best validation accuracy! iteration:5220 accuracy: 0.6610559225082397\n",
      "prediction:  0.66114634\n",
      "epoch 202 \n",
      "0.044497654\n",
      "0.6612399\n",
      "Best validation accuracy! iteration:5240 accuracy: 0.6612399220466614\n",
      "prediction:  0.66133994\n",
      "epoch 203 \n",
      "0.027081275\n",
      "0.6614425\n",
      "Best validation accuracy! iteration:5260 accuracy: 0.6614425182342529\n",
      "prediction:  0.6615578\n",
      "epoch 204 \n",
      "0.0695764\n",
      "0.66163844\n",
      "Best validation accuracy! iteration:5280 accuracy: 0.6616384387016296\n",
      "prediction:  0.6617267\n",
      "0.0389808\n",
      "0.6618261\n",
      "Best validation accuracy! iteration:5300 accuracy: 0.6618260741233826\n",
      "prediction:  0.66194034\n",
      "epoch 205 \n",
      "0.02357973\n",
      "0.66202927\n",
      "Best validation accuracy! iteration:5320 accuracy: 0.6620292663574219\n",
      "prediction:  0.6621325\n",
      "epoch 206 \n",
      "0.019938871\n",
      "0.66221625\n",
      "Best validation accuracy! iteration:5340 accuracy: 0.6622162461280823\n",
      "prediction:  0.6623109\n",
      "epoch 207 \n",
      "0.0072618434\n",
      "0.6624063\n",
      "Best validation accuracy! iteration:5360 accuracy: 0.662406325340271\n",
      "prediction:  0.6625053\n",
      "0.017981509\n",
      "0.66260004\n",
      "Best validation accuracy! iteration:5380 accuracy: 0.662600040435791\n",
      "prediction:  0.6626894\n",
      "epoch 208 \n",
      "0.006176256\n",
      "0.66276276\n",
      "Best validation accuracy! iteration:5400 accuracy: 0.6627627611160278\n",
      "prediction:  0.66286755\n",
      "epoch 209 \n",
      "0.01242067\n",
      "0.66296756\n",
      "Best validation accuracy! iteration:5420 accuracy: 0.6629675626754761\n",
      "prediction:  0.66307276\n",
      "epoch 210 \n",
      "0.050184097\n",
      "0.6631626\n",
      "Best validation accuracy! iteration:5440 accuracy: 0.6631625890731812\n",
      "prediction:  0.6632565\n",
      "0.013328063\n",
      "0.6633275\n",
      "Best validation accuracy! iteration:5460 accuracy: 0.6633275151252747\n",
      "prediction:  0.6634202\n",
      "epoch 211 \n",
      "0.037383378\n",
      "0.6634895\n",
      "Best validation accuracy! iteration:5480 accuracy: 0.6634895205497742\n",
      "prediction:  0.66357064\n",
      "epoch 212 \n",
      "0.07061301\n",
      "0.66364163\n",
      "Best validation accuracy! iteration:5500 accuracy: 0.663641631603241\n",
      "prediction:  0.66371346\n",
      "epoch 213 \n",
      "0.03470235\n",
      "0.66377574\n",
      "Best validation accuracy! iteration:5520 accuracy: 0.6637757420539856\n",
      "prediction:  0.6638432\n",
      "epoch 214 \n",
      "0.092558876\n",
      "0.6639012\n",
      "Best validation accuracy! iteration:5540 accuracy: 0.6639012098312378\n",
      "prediction:  0.663965\n",
      "0.0535275\n",
      "0.66404694\n",
      "Best validation accuracy! iteration:5560 accuracy: 0.6640469431877136\n",
      "prediction:  0.6641302\n",
      "epoch 215 \n",
      "0.06923582\n",
      "0.66420025\n",
      "Best validation accuracy! iteration:5580 accuracy: 0.6642002463340759\n",
      "prediction:  0.66427594\n",
      "epoch 216 \n",
      "0.025691904\n",
      "0.6643546\n",
      "Best validation accuracy! iteration:5600 accuracy: 0.6643546223640442\n",
      "prediction:  0.66443723\n",
      "epoch 217 \n",
      "0.008309623\n",
      "0.6645255\n",
      "Best validation accuracy! iteration:5620 accuracy: 0.6645255088806152\n",
      "prediction:  0.6646247\n",
      "0.034417618\n",
      "0.6647256\n",
      "Best validation accuracy! iteration:5640 accuracy: 0.6647256016731262\n",
      "prediction:  0.66481346\n",
      "epoch 218 \n",
      "0.03055613\n",
      "0.6648956\n",
      "Best validation accuracy! iteration:5660 accuracy: 0.6648955941200256\n",
      "prediction:  0.6649632\n",
      "epoch 219 \n",
      "0.05113393\n",
      "0.66503364\n",
      "Best validation accuracy! iteration:5680 accuracy: 0.6650336384773254\n",
      "prediction:  0.66511023\n",
      "epoch 220 \n",
      "0.010575494\n",
      "0.66520345\n",
      "Best validation accuracy! iteration:5700 accuracy: 0.6652034521102905\n",
      "prediction:  0.66528106\n",
      "0.030781996\n",
      "0.66536415\n",
      "Best validation accuracy! iteration:5720 accuracy: 0.665364146232605\n",
      "prediction:  0.66544807\n",
      "epoch 221 \n",
      "0.050258346\n",
      "0.66554004\n",
      "Best validation accuracy! iteration:5740 accuracy: 0.6655400395393372\n",
      "prediction:  0.66562015\n",
      "epoch 222 \n",
      "0.05311279\n",
      "0.66569793\n",
      "Best validation accuracy! iteration:5760 accuracy: 0.6656979322433472\n",
      "prediction:  0.66578066\n",
      "epoch 223 \n",
      "0.026151221\n",
      "0.6658537\n",
      "Best validation accuracy! iteration:5780 accuracy: 0.6658536791801453\n",
      "prediction:  0.6659187\n",
      "epoch 224 \n",
      "0.034712546\n",
      "0.6659845\n",
      "Best validation accuracy! iteration:5800 accuracy: 0.6659845113754272\n",
      "prediction:  0.6660594\n",
      "0.04759569\n",
      "0.6661263\n",
      "Best validation accuracy! iteration:5820 accuracy: 0.6661263108253479\n",
      "prediction:  0.6661832\n",
      "epoch 225 \n",
      "0.07131807\n",
      "0.66624135\n",
      "Best validation accuracy! iteration:5840 accuracy: 0.6662413477897644\n",
      "prediction:  0.6663009\n",
      "epoch 226 \n",
      "0.0422569\n",
      "0.6663623\n",
      "Best validation accuracy! iteration:5860 accuracy: 0.6663622856140137\n",
      "prediction:  0.666424\n",
      "epoch 227 \n",
      "0.01965449\n",
      "0.6665075\n",
      "Best validation accuracy! iteration:5880 accuracy: 0.6665074825286865\n",
      "prediction:  0.6665892\n",
      "0.026160598\n",
      "0.66667926\n",
      "Best validation accuracy! iteration:5900 accuracy: 0.6666792631149292\n",
      "prediction:  0.6667446\n",
      "epoch 228 \n",
      "0.018985856\n",
      "0.666799\n",
      "Best validation accuracy! iteration:5920 accuracy: 0.666799008846283\n",
      "prediction:  0.66686493\n",
      "epoch 229 \n",
      "0.017088234\n",
      "0.6669392\n",
      "Best validation accuracy! iteration:5940 accuracy: 0.6669391989707947\n",
      "prediction:  0.6670219\n",
      "epoch 230 \n",
      "0.018734781\n",
      "0.6671169\n",
      "Best validation accuracy! iteration:5960 accuracy: 0.6671168804168701\n",
      "prediction:  0.667208\n",
      "0.044950265\n",
      "0.6672893\n",
      "Best validation accuracy! iteration:5980 accuracy: 0.6672893166542053\n",
      "prediction:  0.6673693\n",
      "epoch 231 \n",
      "0.039884653\n",
      "0.6674465\n",
      "Best validation accuracy! iteration:6000 accuracy: 0.667446494102478\n",
      "prediction:  0.6675185\n",
      "epoch 232 \n",
      "0.03538997\n",
      "0.6676017\n",
      "Best validation accuracy! iteration:6020 accuracy: 0.6676017045974731\n",
      "prediction:  0.66768116\n",
      "epoch 233 \n",
      "0.00992168\n",
      "0.6677693\n",
      "Best validation accuracy! iteration:6040 accuracy: 0.6677693128585815\n",
      "prediction:  0.6678487\n",
      "epoch 234 \n",
      "0.026968965\n",
      "0.6679288\n",
      "Best validation accuracy! iteration:6060 accuracy: 0.6679288148880005\n",
      "prediction:  0.6680027\n",
      "0.003469701\n",
      "0.6680868\n",
      "Best validation accuracy! iteration:6080 accuracy: 0.6680868268013\n",
      "prediction:  0.66815823\n",
      "epoch 235 \n",
      "0.012703613\n",
      "0.6682245\n",
      "Best validation accuracy! iteration:6100 accuracy: 0.6682245135307312\n",
      "prediction:  0.6683078\n",
      "epoch 236 \n",
      "0.015255114\n",
      "0.66838145\n",
      "Best validation accuracy! iteration:6120 accuracy: 0.6683814525604248\n",
      "prediction:  0.66844654\n",
      "epoch 237 \n",
      "0.016208274\n",
      "0.66853154\n",
      "Best validation accuracy! iteration:6140 accuracy: 0.6685315370559692\n",
      "prediction:  0.6686167\n",
      "0.0075566666\n",
      "0.66869426\n",
      "Best validation accuracy! iteration:6160 accuracy: 0.668694257736206\n",
      "prediction:  0.66878814\n",
      "epoch 238 \n",
      "0.049126394\n",
      "0.6688603\n",
      "Best validation accuracy! iteration:6180 accuracy: 0.6688603162765503\n",
      "prediction:  0.66893375\n",
      "epoch 239 \n",
      "0.018090712\n",
      "0.6689938\n",
      "Best validation accuracy! iteration:6200 accuracy: 0.6689937710762024\n",
      "prediction:  0.66905415\n",
      "epoch 240 \n",
      "0.03207606\n",
      "0.66912687\n",
      "Best validation accuracy! iteration:6220 accuracy: 0.6691268682479858\n",
      "prediction:  0.6691921\n",
      "0.014557617\n",
      "0.6692552\n",
      "Best validation accuracy! iteration:6240 accuracy: 0.6692551970481873\n",
      "prediction:  0.6693321\n",
      "epoch 241 \n",
      "0.028642964\n",
      "0.6694005\n",
      "Best validation accuracy! iteration:6260 accuracy: 0.6694005131721497\n",
      "prediction:  0.66947836\n",
      "epoch 242 \n",
      "0.03038715\n",
      "0.6695497\n",
      "Best validation accuracy! iteration:6280 accuracy: 0.6695497035980225\n",
      "prediction:  0.6696246\n",
      "epoch 243 \n",
      "0.011231581\n",
      "0.6697046\n",
      "Best validation accuracy! iteration:6300 accuracy: 0.6697046160697937\n",
      "prediction:  0.6697705\n",
      "epoch 244 \n",
      "0.017409327\n",
      "0.6698352\n",
      "Best validation accuracy! iteration:6320 accuracy: 0.6698352098464966\n",
      "prediction:  0.66991305\n",
      "0.031016178\n",
      "0.6699707\n",
      "Best validation accuracy! iteration:6340 accuracy: 0.669970691204071\n",
      "prediction:  0.6700357\n",
      "epoch 245 \n",
      "0.046143923\n",
      "0.6701086\n",
      "Best validation accuracy! iteration:6360 accuracy: 0.6701086163520813\n",
      "prediction:  0.67018265\n",
      "epoch 246 \n",
      "0.021281539\n",
      "0.6702579\n",
      "Best validation accuracy! iteration:6380 accuracy: 0.6702579259872437\n",
      "prediction:  0.6703386\n",
      "epoch 247 \n",
      "0.010546415\n",
      "0.6704157\n",
      "Best validation accuracy! iteration:6400 accuracy: 0.6704156994819641\n",
      "prediction:  0.6704907\n",
      "0.0022732425\n",
      "0.6705734\n",
      "Best validation accuracy! iteration:6420 accuracy: 0.6705734133720398\n",
      "prediction:  0.6706484\n",
      "epoch 248 \n",
      "0.006741835\n",
      "0.6707217\n",
      "Best validation accuracy! iteration:6440 accuracy: 0.670721709728241\n",
      "prediction:  0.67079437\n",
      "epoch 249 \n",
      "0.033350606\n",
      "0.6708696\n",
      "Best validation accuracy! iteration:6460 accuracy: 0.6708695888519287\n",
      "prediction:  0.6709334\n",
      "epoch 250 \n",
      "0.09117427\n",
      "0.6709873\n",
      "Best validation accuracy! iteration:6480 accuracy: 0.6709873080253601\n",
      "prediction:  0.6710304\n",
      "0.038163275\n",
      "0.6710941\n",
      "Best validation accuracy! iteration:6500 accuracy: 0.6710941195487976\n",
      "prediction:  0.67116094\n",
      "epoch 251 \n",
      "0.077006616\n",
      "0.67120486\n",
      "Best validation accuracy! iteration:6520 accuracy: 0.6712048649787903\n",
      "prediction:  0.6712501\n",
      "epoch 252 \n",
      "0.025048435\n",
      "0.6713012\n",
      "Best validation accuracy! iteration:6540 accuracy: 0.6713011860847473\n",
      "prediction:  0.67136997\n",
      "epoch 253 \n",
      "0.041838\n",
      "0.67142254\n",
      "Best validation accuracy! iteration:6560 accuracy: 0.67142254114151\n",
      "prediction:  0.67148316\n",
      "epoch 254 \n",
      "0.024128534\n",
      "0.6715354\n",
      "Best validation accuracy! iteration:6580 accuracy: 0.6715353727340698\n",
      "prediction:  0.6715975\n",
      "0.017857393\n",
      "0.67164755\n",
      "Best validation accuracy! iteration:6600 accuracy: 0.6716475486755371\n",
      "prediction:  0.6717093\n",
      "epoch 255 \n",
      "0.010638118\n",
      "0.67175996\n",
      "Best validation accuracy! iteration:6620 accuracy: 0.6717599630355835\n",
      "prediction:  0.6718259\n",
      "epoch 256 \n",
      "0.012651486\n",
      "0.6718866\n",
      "Best validation accuracy! iteration:6640 accuracy: 0.6718866229057312\n",
      "prediction:  0.67195535\n",
      "epoch 257 \n",
      "0.006976598\n",
      "0.67200667\n",
      "Best validation accuracy! iteration:6660 accuracy: 0.6720066666603088\n",
      "prediction:  0.67207\n",
      "0.0119028175\n",
      "0.6721359\n",
      "Best validation accuracy! iteration:6680 accuracy: 0.6721358895301819\n",
      "prediction:  0.6722087\n",
      "epoch 258 \n",
      "0.01732471\n",
      "0.672258\n",
      "Best validation accuracy! iteration:6700 accuracy: 0.6722580194473267\n",
      "prediction:  0.67232424\n",
      "epoch 259 \n",
      "0.017953211\n",
      "0.6723893\n",
      "Best validation accuracy! iteration:6720 accuracy: 0.6723893284797668\n",
      "prediction:  0.6724667\n",
      "epoch 260 \n",
      "0.0434523\n",
      "0.67253006\n",
      "Best validation accuracy! iteration:6740 accuracy: 0.6725300550460815\n",
      "prediction:  0.6725865\n",
      "0.024098856\n",
      "0.6726406\n",
      "Best validation accuracy! iteration:6760 accuracy: 0.6726406216621399\n",
      "prediction:  0.67271316\n",
      "epoch 261 \n",
      "0.01853089\n",
      "0.67275184\n",
      "Best validation accuracy! iteration:6780 accuracy: 0.6727518439292908\n",
      "prediction:  0.672805\n",
      "epoch 262 \n",
      "0.044994086\n",
      "0.6728597\n",
      "Best validation accuracy! iteration:6800 accuracy: 0.6728597283363342\n",
      "prediction:  0.6729201\n",
      "epoch 263 \n",
      "0.013748868\n",
      "0.6729776\n",
      "Best validation accuracy! iteration:6820 accuracy: 0.6729776263237\n",
      "prediction:  0.67302877\n",
      "epoch 264 \n",
      "0.005330615\n",
      "0.6730794\n",
      "Best validation accuracy! iteration:6840 accuracy: 0.6730793714523315\n",
      "prediction:  0.6731417\n",
      "0.0135439895\n",
      "0.6731775\n",
      "Best validation accuracy! iteration:6860 accuracy: 0.6731774806976318\n",
      "prediction:  0.6732281\n",
      "epoch 265 \n",
      "0.019107928\n",
      "0.6732895\n",
      "Best validation accuracy! iteration:6880 accuracy: 0.6732894778251648\n",
      "prediction:  0.6733498\n",
      "epoch 266 \n",
      "0.015396185\n",
      "0.6734152\n",
      "Best validation accuracy! iteration:6900 accuracy: 0.6734151840209961\n",
      "prediction:  0.6734799\n",
      "epoch 267 \n",
      "0.038860608\n",
      "0.6735501\n",
      "Best validation accuracy! iteration:6920 accuracy: 0.6735501289367676\n",
      "prediction:  0.67361104\n",
      "0.012502739\n",
      "0.6736709\n",
      "Best validation accuracy! iteration:6940 accuracy: 0.6736708879470825\n",
      "prediction:  0.673734\n",
      "epoch 268 \n",
      "0.012809016\n",
      "0.6737957\n",
      "Best validation accuracy! iteration:6960 accuracy: 0.6737957000732422\n",
      "prediction:  0.6738477\n",
      "epoch 269 \n",
      "0.013185528\n",
      "0.67389995\n",
      "Best validation accuracy! iteration:6980 accuracy: 0.6738999485969543\n",
      "prediction:  0.67394906\n",
      "epoch 270 \n",
      "0.026137779\n",
      "0.6740058\n",
      "Best validation accuracy! iteration:7000 accuracy: 0.6740058064460754\n",
      "prediction:  0.6740533\n",
      "0.01507752\n",
      "0.6741234\n",
      "Best validation accuracy! iteration:7020 accuracy: 0.6741234064102173\n",
      "prediction:  0.67418563\n",
      "epoch 271 \n",
      "0.019847954\n",
      "0.6742468\n",
      "Best validation accuracy! iteration:7040 accuracy: 0.6742467880249023\n",
      "prediction:  0.6743018\n",
      "epoch 272 \n",
      "0.017303554\n",
      "0.6743524\n",
      "Best validation accuracy! iteration:7060 accuracy: 0.6743524074554443\n",
      "prediction:  0.67442286\n",
      "epoch 273 \n",
      "0.00542438\n",
      "0.6744813\n",
      "Best validation accuracy! iteration:7080 accuracy: 0.6744812726974487\n",
      "prediction:  0.6745297\n",
      "epoch 274 \n",
      "0.012621115\n",
      "0.674581\n",
      "Best validation accuracy! iteration:7100 accuracy: 0.674580991268158\n",
      "prediction:  0.67463887\n",
      "0.0062334337\n",
      "0.67469954\n",
      "Best validation accuracy! iteration:7120 accuracy: 0.6746995449066162\n",
      "prediction:  0.6747609\n",
      "epoch 275 \n",
      "0.013015164\n",
      "0.6748124\n",
      "Best validation accuracy! iteration:7140 accuracy: 0.674812376499176\n",
      "prediction:  0.6748705\n",
      "epoch 276 \n",
      "0.014895416\n",
      "0.6749225\n",
      "Best validation accuracy! iteration:7160 accuracy: 0.674922525882721\n",
      "prediction:  0.6749706\n",
      "epoch 277 \n",
      "0.029923193\n",
      "0.6750178\n",
      "Best validation accuracy! iteration:7180 accuracy: 0.675017774105072\n",
      "prediction:  0.6750644\n",
      "0.019176843\n",
      "0.67512506\n",
      "Best validation accuracy! iteration:7200 accuracy: 0.6751250624656677\n",
      "prediction:  0.6751914\n",
      "epoch 278 \n",
      "0.009649569\n",
      "0.6752517\n",
      "Best validation accuracy! iteration:7220 accuracy: 0.6752517223358154\n",
      "prediction:  0.67530066\n",
      "epoch 279 \n",
      "0.033887062\n",
      "0.6753482\n",
      "Best validation accuracy! iteration:7240 accuracy: 0.6753482222557068\n",
      "prediction:  0.6753865\n",
      "epoch 280 \n",
      "0.016022597\n",
      "0.6754342\n",
      "Best validation accuracy! iteration:7260 accuracy: 0.6754341721534729\n",
      "prediction:  0.6754896\n",
      "0.006910133\n",
      "0.67554945\n",
      "Best validation accuracy! iteration:7280 accuracy: 0.6755494475364685\n",
      "prediction:  0.67560995\n",
      "epoch 281 \n",
      "0.019853653\n",
      "0.675667\n",
      "Best validation accuracy! iteration:7300 accuracy: 0.6756669878959656\n",
      "prediction:  0.6757341\n",
      "epoch 282 \n",
      "0.0094450805\n",
      "0.6757933\n",
      "Best validation accuracy! iteration:7320 accuracy: 0.6757932901382446\n",
      "prediction:  0.6758519\n",
      "epoch 283 \n",
      "0.009788861\n",
      "0.6759123\n",
      "Best validation accuracy! iteration:7340 accuracy: 0.6759123206138611\n",
      "prediction:  0.6759755\n",
      "epoch 284 \n",
      "0.015127811\n",
      "0.6760173\n",
      "Best validation accuracy! iteration:7360 accuracy: 0.6760172843933105\n",
      "prediction:  0.676065\n",
      "0.01699479\n",
      "0.6761188\n",
      "Best validation accuracy! iteration:7380 accuracy: 0.676118791103363\n",
      "prediction:  0.67617565\n",
      "epoch 285 \n",
      "0.012300972\n",
      "0.6762295\n",
      "Best validation accuracy! iteration:7400 accuracy: 0.6762294769287109\n",
      "prediction:  0.67627794\n",
      "epoch 286 \n",
      "0.010321719\n",
      "0.67634\n",
      "Best validation accuracy! iteration:7420 accuracy: 0.6763399839401245\n",
      "prediction:  0.6763999\n",
      "epoch 287 \n",
      "0.020317411\n",
      "0.6764548\n",
      "Best validation accuracy! iteration:7440 accuracy: 0.6764547824859619\n",
      "prediction:  0.6765079\n",
      "0.019328728\n",
      "0.6765568\n",
      "Best validation accuracy! iteration:7460 accuracy: 0.6765568256378174\n",
      "prediction:  0.67660886\n",
      "epoch 288 \n",
      "0.008613103\n",
      "0.6766672\n",
      "Best validation accuracy! iteration:7480 accuracy: 0.6766672134399414\n",
      "prediction:  0.6767314\n",
      "epoch 289 \n",
      "0.02773471\n",
      "0.676781\n",
      "Best validation accuracy! iteration:7500 accuracy: 0.6767809987068176\n",
      "prediction:  0.6768336\n",
      "epoch 290 \n",
      "0.007518209\n",
      "0.6768761\n",
      "Best validation accuracy! iteration:7520 accuracy: 0.6768761277198792\n",
      "prediction:  0.67692816\n",
      "0.013367445\n",
      "0.6769648\n",
      "Best validation accuracy! iteration:7540 accuracy: 0.6769648194313049\n",
      "prediction:  0.6769987\n",
      "epoch 291 \n",
      "0.018178297\n",
      "0.67703277\n",
      "Best validation accuracy! iteration:7560 accuracy: 0.6770327687263489\n",
      "prediction:  0.67707556\n",
      "epoch 292 \n",
      "0.02412127\n",
      "0.6771099\n",
      "Best validation accuracy! iteration:7580 accuracy: 0.6771098971366882\n",
      "prediction:  0.6771639\n",
      "epoch 293 \n",
      "0.070840776\n",
      "0.6772182\n",
      "Best validation accuracy! iteration:7600 accuracy: 0.6772181987762451\n",
      "prediction:  0.6772751\n",
      "epoch 294 \n",
      "0.053503975\n",
      "0.6773106\n",
      "Best validation accuracy! iteration:7620 accuracy: 0.677310585975647\n",
      "prediction:  0.67736566\n",
      "0.017250711\n",
      "0.6774048\n",
      "Best validation accuracy! iteration:7640 accuracy: 0.6774048209190369\n",
      "prediction:  0.67744356\n",
      "epoch 295 \n",
      "0.035908435\n",
      "0.67749196\n",
      "Best validation accuracy! iteration:7660 accuracy: 0.6774919629096985\n",
      "prediction:  0.6775257\n",
      "epoch 296 \n",
      "0.041183677\n",
      "0.67758834\n",
      "Best validation accuracy! iteration:7680 accuracy: 0.6775883436203003\n",
      "prediction:  0.6776391\n",
      "epoch 297 \n",
      "0.0079666935\n",
      "0.6777092\n",
      "Best validation accuracy! iteration:7700 accuracy: 0.6777092218399048\n",
      "prediction:  0.67777455\n",
      "0.011984643\n",
      "0.67783654\n",
      "Best validation accuracy! iteration:7720 accuracy: 0.677836537361145\n",
      "prediction:  0.6779003\n",
      "epoch 298 \n",
      "0.0021836483\n",
      "0.6779546\n",
      "Best validation accuracy! iteration:7740 accuracy: 0.6779546141624451\n",
      "prediction:  0.6780146\n",
      "epoch 299 \n",
      "0.0040089134\n",
      "0.6780728\n",
      "Best validation accuracy! iteration:7760 accuracy: 0.6780728101730347\n",
      "prediction:  0.67813134\n",
      "epoch 300 \n",
      "0.012902452\n",
      "0.67818195\n",
      "Best validation accuracy! iteration:7780 accuracy: 0.6781819462776184\n",
      "prediction:  0.6782313\n",
      "0.034490883\n",
      "0.67827857\n",
      "Best validation accuracy! iteration:7800 accuracy: 0.6782785654067993\n",
      "prediction:  0.67832\n",
      "epoch 301 \n",
      "0.040867742\n",
      "0.67836314\n",
      "Best validation accuracy! iteration:7820 accuracy: 0.6783631443977356\n",
      "prediction:  0.67841893\n",
      "epoch 302 \n",
      "0.037422758\n",
      "0.6784627\n",
      "Best validation accuracy! iteration:7840 accuracy: 0.6784626841545105\n",
      "prediction:  0.6785166\n",
      "epoch 303 \n",
      "0.024163825\n",
      "0.6785716\n",
      "Best validation accuracy! iteration:7860 accuracy: 0.6785715818405151\n",
      "prediction:  0.67862105\n",
      "epoch 304 \n",
      "0.060804132\n",
      "0.6786521\n",
      "Best validation accuracy! iteration:7880 accuracy: 0.6786521077156067\n",
      "prediction:  0.67869073\n",
      "0.024215123\n",
      "0.6787296\n",
      "Best validation accuracy! iteration:7900 accuracy: 0.6787295937538147\n",
      "prediction:  0.6787627\n",
      "epoch 305 \n",
      "0.06802104\n",
      "0.678815\n",
      "Best validation accuracy! iteration:7920 accuracy: 0.6788150072097778\n",
      "prediction:  0.6788573\n",
      "epoch 306 \n",
      "0.013931216\n",
      "0.6788996\n",
      "Best validation accuracy! iteration:7940 accuracy: 0.6788995862007141\n",
      "prediction:  0.67894626\n",
      "epoch 307 \n",
      "0.035351943\n",
      "0.67898303\n",
      "Best validation accuracy! iteration:7960 accuracy: 0.6789830327033997\n",
      "prediction:  0.67903364\n",
      "0.01751247\n",
      "0.679057\n",
      "Best validation accuracy! iteration:7980 accuracy: 0.6790570020675659\n",
      "prediction:  0.6790927\n",
      "epoch 308 \n",
      "0.02425459\n",
      "0.6791362\n",
      "Best validation accuracy! iteration:8000 accuracy: 0.6791362166404724\n",
      "prediction:  0.67918074\n",
      "epoch 309 \n",
      "0.020217022\n",
      "0.67922664\n",
      "Best validation accuracy! iteration:8020 accuracy: 0.6792266368865967\n",
      "prediction:  0.6792717\n",
      "epoch 310 \n",
      "0.033373404\n",
      "0.67929685\n",
      "Best validation accuracy! iteration:8040 accuracy: 0.6792968511581421\n",
      "prediction:  0.67932636\n",
      "0.0104938615\n",
      "0.6793607\n",
      "Best validation accuracy! iteration:8060 accuracy: 0.6793606877326965\n",
      "prediction:  0.67939603\n",
      "epoch 311 \n",
      "0.024843602\n",
      "0.6794317\n",
      "Best validation accuracy! iteration:8080 accuracy: 0.679431676864624\n",
      "prediction:  0.6794628\n",
      "epoch 312 \n",
      "0.028119\n",
      "0.6794971\n",
      "Best validation accuracy! iteration:8100 accuracy: 0.6794971227645874\n",
      "prediction:  0.6795314\n",
      "epoch 313 \n",
      "0.0133794015\n",
      "0.6795804\n",
      "Best validation accuracy! iteration:8120 accuracy: 0.6795803904533386\n",
      "prediction:  0.679616\n",
      "epoch 314 \n",
      "0.026206646\n",
      "0.6796592\n",
      "Best validation accuracy! iteration:8140 accuracy: 0.6796591877937317\n",
      "prediction:  0.6796975\n",
      "0.023543619\n",
      "0.67974013\n",
      "Best validation accuracy! iteration:8160 accuracy: 0.6797401309013367\n",
      "prediction:  0.6797772\n",
      "epoch 315 \n",
      "0.020149436\n",
      "0.6798299\n",
      "Best validation accuracy! iteration:8180 accuracy: 0.6798298954963684\n",
      "prediction:  0.67987007\n",
      "epoch 316 \n",
      "0.020804072\n",
      "0.6799126\n",
      "Best validation accuracy! iteration:8200 accuracy: 0.6799126267433167\n",
      "prediction:  0.67995876\n",
      "epoch 317 \n",
      "0.026619952\n",
      "0.68000704\n",
      "Best validation accuracy! iteration:8220 accuracy: 0.6800070405006409\n",
      "prediction:  0.6800522\n",
      "0.019738654\n",
      "0.68009436\n",
      "Best validation accuracy! iteration:8240 accuracy: 0.6800943613052368\n",
      "prediction:  0.6801339\n",
      "epoch 318 \n",
      "0.020911608\n",
      "0.68017113\n",
      "Best validation accuracy! iteration:8260 accuracy: 0.6801711320877075\n",
      "prediction:  0.6801985\n",
      "epoch 319 \n",
      "0.012297766\n",
      "0.6802471\n",
      "Best validation accuracy! iteration:8280 accuracy: 0.6802471280097961\n",
      "prediction:  0.68029606\n",
      "epoch 320 \n",
      "0.015444298\n",
      "0.6803358\n",
      "Best validation accuracy! iteration:8300 accuracy: 0.6803358197212219\n",
      "prediction:  0.68037874\n",
      "0.013453901\n",
      "0.6804226\n",
      "Best validation accuracy! iteration:8320 accuracy: 0.6804226040840149\n",
      "prediction:  0.6804697\n",
      "epoch 321 \n",
      "0.010514273\n",
      "0.6805198\n",
      "Best validation accuracy! iteration:8340 accuracy: 0.6805198192596436\n",
      "prediction:  0.6805706\n",
      "epoch 322 \n",
      "0.011021802\n",
      "0.680627\n",
      "Best validation accuracy! iteration:8360 accuracy: 0.6806269884109497\n",
      "prediction:  0.6806739\n",
      "epoch 323 \n",
      "0.05443317\n",
      "0.68070924\n",
      "Best validation accuracy! iteration:8380 accuracy: 0.6807092428207397\n",
      "prediction:  0.6807506\n",
      "epoch 324 \n",
      "0.019490197\n",
      "0.6807893\n",
      "Best validation accuracy! iteration:8400 accuracy: 0.6807892918586731\n",
      "prediction:  0.68083084\n",
      "0.025364848\n",
      "0.68087184\n",
      "Best validation accuracy! iteration:8420 accuracy: 0.680871844291687\n",
      "prediction:  0.6809107\n",
      "epoch 325 \n",
      "0.036082324\n",
      "0.6809533\n",
      "Best validation accuracy! iteration:8440 accuracy: 0.680953323841095\n",
      "prediction:  0.68099195\n",
      "epoch 326 \n",
      "0.031396996\n",
      "0.6810198\n",
      "Best validation accuracy! iteration:8460 accuracy: 0.6810197830200195\n",
      "prediction:  0.6810547\n",
      "epoch 327 \n",
      "0.017686252\n",
      "0.6810973\n",
      "Best validation accuracy! iteration:8480 accuracy: 0.6810973286628723\n",
      "prediction:  0.68114907\n",
      "0.040756904\n",
      "0.6811904\n",
      "Best validation accuracy! iteration:8500 accuracy: 0.6811903715133667\n",
      "prediction:  0.68123484\n",
      "epoch 328 \n",
      "0.0043944423\n",
      "0.6812809\n",
      "Best validation accuracy! iteration:8520 accuracy: 0.6812809109687805\n",
      "prediction:  0.68132615\n",
      "epoch 329 \n",
      "0.019762456\n",
      "0.68136394\n",
      "Best validation accuracy! iteration:8540 accuracy: 0.6813639402389526\n",
      "prediction:  0.681409\n",
      "epoch 330 \n",
      "0.0047587953\n",
      "0.68145084\n",
      "Best validation accuracy! iteration:8560 accuracy: 0.6814508438110352\n",
      "prediction:  0.6815069\n",
      "0.007959368\n",
      "0.68155336\n",
      "Best validation accuracy! iteration:8580 accuracy: 0.6815533638000488\n",
      "prediction:  0.68160224\n",
      "epoch 331 \n",
      "0.03297767\n",
      "0.6816429\n",
      "Best validation accuracy! iteration:8600 accuracy: 0.6816428899765015\n",
      "prediction:  0.6816943\n",
      "epoch 332 \n",
      "0.02715515\n",
      "0.68173337\n",
      "Best validation accuracy! iteration:8620 accuracy: 0.6817333698272705\n",
      "prediction:  0.6817745\n",
      "epoch 333 \n",
      "0.0034789622\n",
      "0.68182105\n",
      "Best validation accuracy! iteration:8640 accuracy: 0.6818210482597351\n",
      "prediction:  0.6818699\n",
      "epoch 334 \n",
      "0.012669563\n",
      "0.6819079\n",
      "Best validation accuracy! iteration:8660 accuracy: 0.6819078922271729\n",
      "prediction:  0.6819555\n",
      "0.010161081\n",
      "0.6820062\n",
      "Best validation accuracy! iteration:8680 accuracy: 0.6820061802864075\n",
      "prediction:  0.68205804\n",
      "epoch 335 \n",
      "0.01952216\n",
      "0.682095\n",
      "Best validation accuracy! iteration:8700 accuracy: 0.6820949912071228\n",
      "prediction:  0.68214047\n",
      "epoch 336 \n",
      "0.008538115\n",
      "0.68216825\n",
      "Best validation accuracy! iteration:8720 accuracy: 0.6821682453155518\n",
      "prediction:  0.6822135\n",
      "epoch 337 \n",
      "0.03561697\n",
      "0.6822501\n",
      "Best validation accuracy! iteration:8740 accuracy: 0.6822500824928284\n",
      "prediction:  0.68229586\n",
      "0.028189523\n",
      "0.6823377\n",
      "Best validation accuracy! iteration:8760 accuracy: 0.6823377013206482\n",
      "prediction:  0.682372\n",
      "epoch 338 \n",
      "0.018639488\n",
      "0.6824092\n",
      "Best validation accuracy! iteration:8780 accuracy: 0.6824092268943787\n",
      "prediction:  0.68245494\n",
      "epoch 339 \n",
      "0.013816999\n",
      "0.68247664\n",
      "Best validation accuracy! iteration:8800 accuracy: 0.6824766397476196\n",
      "prediction:  0.6825205\n",
      "epoch 340 \n",
      "0.029893547\n",
      "0.68255097\n",
      "Best validation accuracy! iteration:8820 accuracy: 0.6825509667396545\n",
      "prediction:  0.68259764\n",
      "0.030414788\n",
      "0.6826317\n",
      "Best validation accuracy! iteration:8840 accuracy: 0.6826316714286804\n",
      "prediction:  0.68267006\n",
      "epoch 341 \n",
      "0.02232863\n",
      "0.68269336\n",
      "Best validation accuracy! iteration:8860 accuracy: 0.682693362236023\n",
      "prediction:  0.6827333\n",
      "epoch 342 \n",
      "0.0035641869\n",
      "0.6827778\n",
      "Best validation accuracy! iteration:8880 accuracy: 0.6827778220176697\n",
      "prediction:  0.68282026\n",
      "epoch 343 \n",
      "0.009007104\n",
      "0.6828538\n",
      "Best validation accuracy! iteration:8900 accuracy: 0.6828538179397583\n",
      "prediction:  0.68289065\n",
      "epoch 344 \n",
      "0.03673779\n",
      "0.6829348\n",
      "Best validation accuracy! iteration:8920 accuracy: 0.6829348206520081\n",
      "prediction:  0.6829708\n",
      "0.024410568\n",
      "0.68300736\n",
      "Best validation accuracy! iteration:8940 accuracy: 0.6830073595046997\n",
      "prediction:  0.68304694\n",
      "epoch 345 \n",
      "0.020306312\n",
      "0.6830944\n",
      "Best validation accuracy! iteration:8960 accuracy: 0.6830943822860718\n",
      "prediction:  0.6831414\n",
      "epoch 346 \n",
      "0.019753039\n",
      "0.6831807\n",
      "Best validation accuracy! iteration:8980 accuracy: 0.6831806898117065\n",
      "prediction:  0.68322015\n",
      "epoch 347 \n",
      "0.010273291\n",
      "0.6832536\n",
      "Best validation accuracy! iteration:9000 accuracy: 0.6832535862922668\n",
      "prediction:  0.68329555\n",
      "0.025952192\n",
      "0.6833281\n",
      "Best validation accuracy! iteration:9020 accuracy: 0.6833280920982361\n",
      "prediction:  0.6833726\n",
      "epoch 348 \n",
      "0.07243245\n",
      "0.68339837\n",
      "Best validation accuracy! iteration:9040 accuracy: 0.6833983659744263\n",
      "prediction:  0.683433\n",
      "epoch 349 \n",
      "0.024265217\n",
      "0.6834679\n",
      "Best validation accuracy! iteration:9060 accuracy: 0.6834679245948792\n",
      "prediction:  0.6835071\n",
      "epoch 350 \n",
      "0.012609277\n",
      "0.68354684\n",
      "Best validation accuracy! iteration:9080 accuracy: 0.6835468411445618\n",
      "prediction:  0.6835812\n",
      "0.006945886\n",
      "0.6836184\n",
      "Best validation accuracy! iteration:9100 accuracy: 0.683618426322937\n",
      "prediction:  0.68366057\n",
      "epoch 351 \n",
      "0.016385067\n",
      "0.68369365\n",
      "Best validation accuracy! iteration:9120 accuracy: 0.6836936473846436\n",
      "prediction:  0.6837373\n",
      "epoch 352 \n",
      "0.016563123\n",
      "0.683764\n",
      "Best validation accuracy! iteration:9140 accuracy: 0.6837639808654785\n",
      "prediction:  0.6837939\n",
      "epoch 353 \n",
      "0.024052627\n",
      "0.6838179\n",
      "Best validation accuracy! iteration:9160 accuracy: 0.6838179230690002\n",
      "prediction:  0.68384546\n",
      "epoch 354 \n",
      "0.04271154\n",
      "0.68387586\n",
      "Best validation accuracy! iteration:9180 accuracy: 0.6838758587837219\n",
      "prediction:  0.6839085\n",
      "0.022763047\n",
      "0.68395054\n",
      "Best validation accuracy! iteration:9200 accuracy: 0.6839505434036255\n",
      "prediction:  0.68399864\n",
      "epoch 355 \n",
      "0.010660517\n",
      "0.68404216\n",
      "Best validation accuracy! iteration:9220 accuracy: 0.6840421557426453\n",
      "prediction:  0.6840852\n",
      "epoch 356 \n",
      "0.00614767\n",
      "0.68413436\n",
      "Best validation accuracy! iteration:9240 accuracy: 0.6841343641281128\n",
      "prediction:  0.68418014\n",
      "epoch 357 \n",
      "0.0003743971\n",
      "0.6842294\n",
      "Best validation accuracy! iteration:9260 accuracy: 0.6842293739318848\n",
      "prediction:  0.6842808\n",
      "0.007065099\n",
      "0.6843366\n",
      "Best validation accuracy! iteration:9280 accuracy: 0.6843366026878357\n",
      "prediction:  0.6843839\n",
      "epoch 358 \n",
      "0.01462979\n",
      "0.68441886\n",
      "Best validation accuracy! iteration:9300 accuracy: 0.6844188570976257\n",
      "prediction:  0.68445826\n",
      "epoch 359 \n",
      "0.014958613\n",
      "0.6844962\n",
      "Best validation accuracy! iteration:9320 accuracy: 0.6844962239265442\n",
      "prediction:  0.68453676\n",
      "epoch 360 \n",
      "0.037355985\n",
      "0.6845678\n",
      "Best validation accuracy! iteration:9340 accuracy: 0.6845678091049194\n",
      "prediction:  0.6846062\n",
      "0.015153685\n",
      "0.6846391\n",
      "Best validation accuracy! iteration:9360 accuracy: 0.6846390962600708\n",
      "prediction:  0.68468183\n",
      "epoch 361 \n",
      "0.018727317\n",
      "0.6847216\n",
      "Best validation accuracy! iteration:9380 accuracy: 0.6847215890884399\n",
      "prediction:  0.6847603\n",
      "epoch 362 \n",
      "0.031052874\n",
      "0.68479764\n",
      "Best validation accuracy! iteration:9400 accuracy: 0.6847976446151733\n",
      "prediction:  0.68483174\n",
      "epoch 363 \n",
      "0.016103918\n",
      "0.68485427\n",
      "Best validation accuracy! iteration:9420 accuracy: 0.68485426902771\n",
      "prediction:  0.6848895\n",
      "epoch 364 \n",
      "0.012182382\n",
      "0.684916\n",
      "Best validation accuracy! iteration:9440 accuracy: 0.6849160194396973\n",
      "prediction:  0.6849495\n",
      "0.044627797\n",
      "0.6849782\n",
      "Best validation accuracy! iteration:9460 accuracy: 0.684978187084198\n",
      "prediction:  0.68501186\n",
      "epoch 365 \n",
      "0.03152823\n",
      "0.6850455\n",
      "Best validation accuracy! iteration:9480 accuracy: 0.6850454807281494\n",
      "prediction:  0.68508154\n",
      "epoch 366 \n",
      "0.013154867\n",
      "0.68511057\n",
      "Best validation accuracy! iteration:9500 accuracy: 0.6851105690002441\n",
      "prediction:  0.68514776\n",
      "epoch 367 \n",
      "0.042170554\n",
      "0.6851653\n",
      "Best validation accuracy! iteration:9520 accuracy: 0.685165286064148\n",
      "prediction:  0.6851878\n",
      "0.0046591233\n",
      "0.68523365\n",
      "Best validation accuracy! iteration:9540 accuracy: 0.6852336525917053\n",
      "prediction:  0.6852693\n",
      "epoch 368 \n",
      "0.030238809\n",
      "0.6853055\n",
      "Best validation accuracy! iteration:9560 accuracy: 0.6853054761886597\n",
      "prediction:  0.685335\n",
      "epoch 369 \n",
      "0.0038652758\n",
      "0.6853751\n",
      "Best validation accuracy! iteration:9580 accuracy: 0.6853750944137573\n",
      "prediction:  0.6854108\n",
      "epoch 370 \n",
      "0.01473023\n",
      "0.68545353\n",
      "Best validation accuracy! iteration:9600 accuracy: 0.6854535341262817\n",
      "prediction:  0.68549246\n",
      "0.015182582\n",
      "0.6855338\n",
      "Best validation accuracy! iteration:9620 accuracy: 0.6855338215827942\n",
      "prediction:  0.68557197\n",
      "epoch 371 \n",
      "0.018890759\n",
      "0.6856066\n",
      "Best validation accuracy! iteration:9640 accuracy: 0.6856065988540649\n",
      "prediction:  0.6856474\n",
      "epoch 372 \n",
      "0.024282357\n",
      "0.68568814\n",
      "Best validation accuracy! iteration:9660 accuracy: 0.6856881380081177\n",
      "prediction:  0.68573\n",
      "epoch 373 \n",
      "0.010648694\n",
      "0.6857705\n",
      "Best validation accuracy! iteration:9680 accuracy: 0.6857705116271973\n",
      "prediction:  0.6858104\n",
      "epoch 374 \n",
      "0.012527305\n",
      "0.68584794\n",
      "Best validation accuracy! iteration:9700 accuracy: 0.6858479380607605\n",
      "prediction:  0.68588144\n",
      "0.012369201\n",
      "0.6859102\n",
      "Best validation accuracy! iteration:9720 accuracy: 0.6859102249145508\n",
      "prediction:  0.68594944\n",
      "epoch 375 \n",
      "0.01912429\n",
      "0.68599194\n",
      "Best validation accuracy! iteration:9740 accuracy: 0.6859919428825378\n",
      "prediction:  0.6860267\n",
      "epoch 376 \n",
      "0.01180328\n",
      "0.6860648\n",
      "Best validation accuracy! iteration:9760 accuracy: 0.6860647797584534\n",
      "prediction:  0.68610245\n",
      "epoch 377 \n",
      "0.010065041\n",
      "0.68614125\n",
      "Best validation accuracy! iteration:9780 accuracy: 0.6861412525177002\n",
      "prediction:  0.6861846\n",
      "0.02468393\n",
      "0.68621284\n",
      "Best validation accuracy! iteration:9800 accuracy: 0.6862128376960754\n",
      "prediction:  0.6862517\n",
      "epoch 378 \n",
      "0.030763298\n",
      "0.68628687\n",
      "Best validation accuracy! iteration:9820 accuracy: 0.6862868666648865\n",
      "prediction:  0.686322\n",
      "epoch 379 \n",
      "0.030705398\n",
      "0.6863539\n",
      "Best validation accuracy! iteration:9840 accuracy: 0.6863539218902588\n",
      "prediction:  0.68638945\n",
      "epoch 380 \n",
      "0.045644213\n",
      "0.68641394\n",
      "Best validation accuracy! iteration:9860 accuracy: 0.6864139437675476\n",
      "prediction:  0.68645513\n",
      "0.030039562\n",
      "0.6864938\n",
      "Best validation accuracy! iteration:9880 accuracy: 0.6864938139915466\n",
      "prediction:  0.6865315\n",
      "epoch 381 \n",
      "0.021949735\n",
      "0.6865621\n",
      "Best validation accuracy! iteration:9900 accuracy: 0.6865621209144592\n",
      "prediction:  0.68659025\n",
      "epoch 382 \n",
      "0.037657004\n",
      "0.6866308\n",
      "Best validation accuracy! iteration:9920 accuracy: 0.6866307854652405\n",
      "prediction:  0.6866703\n",
      "epoch 383 \n",
      "0.038549174\n",
      "0.6866949\n",
      "Best validation accuracy! iteration:9940 accuracy: 0.6866949200630188\n",
      "prediction:  0.68672794\n",
      "epoch 384 \n",
      "0.025123041\n",
      "0.68674827\n",
      "Best validation accuracy! iteration:9960 accuracy: 0.6867482662200928\n",
      "prediction:  0.6867845\n",
      "0.055387028\n",
      "0.6868134\n",
      "Best validation accuracy! iteration:9980 accuracy: 0.6868134140968323\n",
      "prediction:  0.6868519\n",
      "epoch 385 \n",
      "0.032355756\n",
      "0.6868903\n",
      "Best validation accuracy! iteration:10000 accuracy: 0.6868903040885925\n",
      "prediction:  0.68692267\n",
      "epoch 386 \n",
      "0.02653076\n",
      "0.6869579\n",
      "Best validation accuracy! iteration:10020 accuracy: 0.6869578957557678\n",
      "prediction:  0.68699193\n",
      "epoch 387 \n",
      "0.015670668\n",
      "0.6870202\n",
      "Best validation accuracy! iteration:10040 accuracy: 0.6870201826095581\n",
      "prediction:  0.6870585\n",
      "0.026757307\n",
      "0.68708754\n",
      "Best validation accuracy! iteration:10060 accuracy: 0.6870875358581543\n",
      "prediction:  0.68712485\n",
      "epoch 388 \n",
      "0.01064838\n",
      "0.6871618\n",
      "Best validation accuracy! iteration:10080 accuracy: 0.6871618032455444\n",
      "prediction:  0.6871942\n",
      "epoch 389 \n",
      "0.009792424\n",
      "0.6872349\n",
      "Best validation accuracy! iteration:10100 accuracy: 0.6872348785400391\n",
      "prediction:  0.6872743\n",
      "epoch 390 \n",
      "0.022507697\n",
      "0.68730944\n",
      "Best validation accuracy! iteration:10120 accuracy: 0.6873094439506531\n",
      "prediction:  0.68734956\n",
      "0.0064456407\n",
      "0.6873938\n",
      "Best validation accuracy! iteration:10140 accuracy: 0.6873937845230103\n",
      "prediction:  0.6874278\n",
      "epoch 391 \n",
      "0.015243601\n",
      "0.6874648\n",
      "Best validation accuracy! iteration:10160 accuracy: 0.6874647736549377\n",
      "prediction:  0.6875052\n",
      "epoch 392 \n",
      "0.039068706\n",
      "0.6875337\n",
      "Best validation accuracy! iteration:10180 accuracy: 0.6875336766242981\n",
      "prediction:  0.6875672\n",
      "epoch 393 \n",
      "0.031106753\n",
      "0.6875988\n",
      "Best validation accuracy! iteration:10200 accuracy: 0.6875988245010376\n",
      "prediction:  0.687634\n",
      "epoch 394 \n",
      "0.0071158693\n",
      "0.6876699\n",
      "Best validation accuracy! iteration:10220 accuracy: 0.6876698732376099\n",
      "prediction:  0.6877125\n",
      "0.0096987635\n",
      "0.6877416\n",
      "Best validation accuracy! iteration:10240 accuracy: 0.6877415776252747\n",
      "prediction:  0.6877823\n",
      "epoch 395 \n",
      "0.006221759\n",
      "0.6878126\n",
      "Best validation accuracy! iteration:10260 accuracy: 0.6878126263618469\n",
      "prediction:  0.6878465\n",
      "epoch 396 \n",
      "0.0061268597\n",
      "0.68788815\n",
      "Best validation accuracy! iteration:10280 accuracy: 0.6878881454467773\n",
      "prediction:  0.6879227\n",
      "epoch 397 \n",
      "0.005135869\n",
      "0.68794584\n",
      "Best validation accuracy! iteration:10300 accuracy: 0.6879458427429199\n",
      "prediction:  0.68798053\n",
      "0.012827352\n",
      "0.68801117\n",
      "Best validation accuracy! iteration:10320 accuracy: 0.6880111694335938\n",
      "prediction:  0.6880414\n",
      "epoch 398 \n",
      "0.00467452\n",
      "0.68807274\n",
      "Best validation accuracy! iteration:10340 accuracy: 0.6880727410316467\n",
      "prediction:  0.68810487\n",
      "epoch 399 \n",
      "0.017914353\n",
      "0.6881292\n",
      "Best validation accuracy! iteration:10360 accuracy: 0.688129186630249\n",
      "prediction:  0.6881696\n",
      "epoch 400 \n",
      "0.011251602\n",
      "0.6882062\n",
      "Best validation accuracy! iteration:10380 accuracy: 0.6882061958312988\n",
      "prediction:  0.6882459\n",
      "0.055050116\n",
      "0.6882858\n",
      "Best validation accuracy! iteration:10400 accuracy: 0.6882858276367188\n",
      "prediction:  0.68832105\n",
      "Traning ends. The best valid accuracy is 0.6882858276367188. Model named cnn_1576394660.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6882858, 0.68832105]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_featmap = (48, 64, 128, 160, 192, 192, 192, 192)\n",
    "fc_units = (3072, 3072)\n",
    "conv_kernel_size = (5, 5, 5, 5, 5, 5, 5, 5)\n",
    "pooling_size = (2, 2, 2, 2, 2, 2, 2, 2)\n",
    "stride_size = (2, 1, 2, 1, 2, 1, 2, 1)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "train_with_pred.train(train, train_label, val, val_label,test, test_label,\n",
    "                conv_featmap=conv_featmap,\n",
    "                fc_units=fc_units,\n",
    "                conv_kernel_size=conv_kernel_size,\n",
    "                pooling_size=pooling_size,\n",
    "                l2_norm=0,\n",
    "                seed=888,\n",
    "                learning_rate=3e-3,\n",
    "                epoch=400,\n",
    "                batch_size=1024,\n",
    "                verbose=False,\n",
    "                stride_size = stride_size,\n",
    "                drop_rate=0             \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.18155146e+00 6.92951488e+00 6.73190594e+00 6.57618475e+00\n",
      " 6.12176991e+00 5.85927820e+00 5.77960920e+00 5.14183044e+00\n",
      " 5.16355896e+00 4.38940620e+00 3.91580367e+00 3.92582011e+00\n",
      " 3.33806992e+00 2.88347220e+00 2.63579774e+00 2.06213427e+00\n",
      " 2.05154753e+00 1.83798361e+00 1.79845023e+00 1.62393546e+00\n",
      " 1.46900713e+00 1.47101653e+00 1.25964165e+00 1.51938105e+00\n",
      " 1.19131541e+00 1.30575979e+00 1.12390435e+00 1.12641263e+00\n",
      " 8.95789802e-01 9.24060881e-01 7.23260045e-01 8.05386662e-01\n",
      " 6.59289062e-01 6.15751326e-01 6.00575030e-01 5.48059404e-01\n",
      " 5.40255725e-01 5.12258172e-01 4.70102638e-01 4.84177947e-01\n",
      " 4.86510932e-01 5.37485003e-01 5.70393145e-01 4.24037009e-01\n",
      " 4.29197431e-01 4.56128120e-01 4.78559881e-01 4.87810969e-01\n",
      " 2.65873164e-01 2.08261386e-01 1.83621541e-01 1.18772328e-01\n",
      " 1.82516813e-01 1.45549938e-01 2.75506407e-01 2.43420556e-01\n",
      " 8.46827030e-02 1.11536145e-01 1.30983070e-01 9.14497375e-02\n",
      " 1.81420073e-01 2.42533207e-01 1.35245383e-01 1.72154441e-01\n",
      " 2.22297072e-01 1.05000407e-01 1.12330683e-01 9.59105492e-02\n",
      " 8.90814662e-02 4.88764308e-02 7.07842484e-02 1.33129716e-01\n",
      " 7.61504397e-02 4.55075987e-02 5.78313880e-02 5.40821105e-02\n",
      " 7.33285025e-02 5.11343442e-02 5.26263528e-02 4.54500988e-02\n",
      " 6.24299087e-02 6.84285909e-02 5.66477142e-02 5.54957800e-02\n",
      " 3.62519994e-02 4.07924913e-02 5.05900607e-02 3.76588479e-02\n",
      " 3.88735682e-02 5.70098944e-02 3.09478361e-02 1.00457676e-01\n",
      " 4.50967513e-02 8.05754811e-02 7.75601491e-02 3.97786908e-02\n",
      " 4.44328636e-02 6.99597672e-02 3.95924449e-02 6.51821271e-02\n",
      " 6.88124523e-02 7.95376897e-02 3.02857049e-02 3.99679318e-02\n",
      " 7.21810162e-02 4.63792980e-02 7.19184801e-02 8.90038162e-02\n",
      " 2.68558264e-02 7.40044490e-02 4.00015488e-02 3.13154273e-02\n",
      " 5.28421216e-02 5.44864647e-02 7.53399357e-02 8.49363953e-02\n",
      " 6.34174198e-02 9.25275907e-02 9.70712751e-02 1.21237420e-01\n",
      " 7.93279260e-02 4.47591580e-02 6.51972070e-02 4.98350523e-02\n",
      " 2.68443879e-02 3.53410840e-02 5.17119840e-02 5.49988337e-02\n",
      " 6.22414574e-02 4.70448770e-02 7.48529434e-02 3.28050181e-02\n",
      " 5.14072441e-02 8.44780654e-02 3.15381698e-02 3.55878398e-02\n",
      " 9.91714820e-02 3.36409919e-02 7.01940209e-02 9.19054598e-02\n",
      " 8.48547742e-02 5.08845411e-02 1.05986178e-01 2.50538047e-02\n",
      " 3.79091538e-02 6.56408221e-02 3.89752351e-02 6.04643114e-02\n",
      " 4.95753027e-02 9.69858170e-02 3.92143205e-02 1.20047159e-01\n",
      " 6.12710938e-02 8.08506683e-02 6.90566674e-02 2.17551477e-02\n",
      " 5.50885126e-02 5.42050861e-02 4.99887317e-02 3.99035178e-02\n",
      " 3.41468789e-02 5.03890477e-02 4.24028561e-02 4.47162390e-02\n",
      " 3.49392965e-02 3.79474871e-02 3.58866714e-02 4.77994122e-02\n",
      " 4.28044572e-02 2.00543851e-02 4.31149900e-02 4.28618751e-02\n",
      " 2.86440477e-02 1.50328465e-02 1.05098613e-01 3.28475013e-02\n",
      " 4.20695171e-02 2.23763864e-02 5.51530123e-02 2.17895266e-02\n",
      " 3.58797498e-02 4.37693112e-02 7.43114799e-02 2.68707220e-02\n",
      " 1.65239647e-02 3.84061858e-02 6.58642175e-03 1.75565425e-02\n",
      " 2.36895625e-02 3.75149176e-02 2.51175612e-02 2.85495557e-02\n",
      " 4.43378240e-02 9.48421210e-02 2.50627156e-02 7.56645575e-02\n",
      " 7.71451071e-02 6.91842511e-02 3.55725065e-02 3.47772315e-02\n",
      " 6.50806129e-02 2.36672964e-02 5.63935079e-02 4.71112691e-02\n",
      " 2.00907663e-02 1.22312307e-02 4.21564095e-02 2.30410490e-02\n",
      " 3.08959540e-02 1.33935660e-02 2.08854433e-02 2.82009952e-02\n",
      " 4.57220860e-02 1.96790565e-02 3.13186236e-02 4.05551344e-02\n",
      " 5.64069599e-02 5.96145727e-02 6.21900745e-02 4.80239838e-02\n",
      " 1.69907957e-02 2.63857283e-02 5.53652942e-02 1.02899238e-01\n",
      " 6.14955053e-02 3.44076380e-02 7.64644220e-02 3.68479565e-02\n",
      " 4.82585914e-02 1.73884004e-01 4.83427569e-02 1.26728974e-02\n",
      " 1.64909530e-02 4.12783101e-02 2.82615293e-02 2.89218873e-02\n",
      " 2.82227136e-02 1.43243540e-02 2.77032554e-02 5.63067757e-02\n",
      " 3.90883014e-02 2.85745356e-02 2.06250474e-02 1.33296894e-02\n",
      " 5.04760779e-02 2.41593383e-02 4.42336015e-02 5.33581898e-02\n",
      " 2.49778405e-02 1.67377833e-02 2.44162567e-02 3.83972973e-02\n",
      " 1.06371911e-02 1.59556903e-02 1.93600170e-02 2.01380756e-02\n",
      " 1.76625997e-02 2.96029728e-02 3.78401019e-02 3.69371325e-02\n",
      " 4.00643237e-02 4.44976538e-02 2.70812754e-02 6.95763975e-02\n",
      " 3.89808007e-02 2.35797297e-02 1.99388713e-02 7.26184342e-03\n",
      " 1.79815087e-02 6.17625611e-03 1.24206701e-02 5.01840971e-02\n",
      " 1.33280633e-02 3.73833776e-02 7.06130117e-02 3.47023495e-02\n",
      " 9.25588757e-02 5.35275005e-02 6.92358166e-02 2.56919041e-02\n",
      " 8.30962323e-03 3.44176181e-02 3.05561293e-02 5.11339307e-02\n",
      " 1.05754938e-02 3.07819955e-02 5.02583459e-02 5.31127900e-02\n",
      " 2.61512212e-02 3.47125456e-02 4.75956909e-02 7.13180676e-02\n",
      " 4.22568992e-02 1.96544901e-02 2.61605978e-02 1.89858563e-02\n",
      " 1.70882344e-02 1.87347811e-02 4.49502654e-02 3.98846529e-02\n",
      " 3.53899710e-02 9.92168020e-03 2.69689653e-02 3.46970093e-03\n",
      " 1.27036134e-02 1.52551141e-02 1.62082743e-02 7.55666662e-03\n",
      " 4.91263941e-02 1.80907119e-02 3.20760608e-02 1.45576168e-02\n",
      " 2.86429636e-02 3.03871501e-02 1.12315807e-02 1.74093265e-02\n",
      " 3.10161784e-02 4.61439230e-02 2.12815385e-02 1.05464151e-02\n",
      " 2.27324245e-03 6.74183480e-03 3.33506055e-02 9.11742672e-02\n",
      " 3.81632745e-02 7.70066157e-02 2.50484347e-02 4.18380015e-02\n",
      " 2.41285339e-02 1.78573932e-02 1.06381178e-02 1.26514863e-02\n",
      " 6.97659794e-03 1.19028175e-02 1.73247103e-02 1.79532114e-02\n",
      " 4.34523001e-02 2.40988564e-02 1.85308903e-02 4.49940860e-02\n",
      " 1.37488684e-02 5.33061521e-03 1.35439895e-02 1.91079285e-02\n",
      " 1.53961852e-02 3.88606079e-02 1.25027392e-02 1.28090158e-02\n",
      " 1.31855281e-02 2.61377785e-02 1.50775202e-02 1.98479537e-02\n",
      " 1.73035543e-02 5.42437984e-03 1.26211150e-02 6.23343373e-03\n",
      " 1.30151641e-02 1.48954159e-02 2.99231932e-02 1.91768426e-02\n",
      " 9.64956917e-03 3.38870622e-02 1.60225965e-02 6.91013318e-03\n",
      " 1.98536534e-02 9.44508053e-03 9.78886057e-03 1.51278106e-02\n",
      " 1.69947892e-02 1.23009719e-02 1.03217186e-02 2.03174111e-02\n",
      " 1.93287283e-02 8.61310307e-03 2.77347099e-02 7.51820905e-03\n",
      " 1.33674452e-02 1.81782972e-02 2.41212696e-02 7.08407760e-02\n",
      " 5.35039753e-02 1.72507111e-02 3.59084345e-02 4.11836766e-02\n",
      " 7.96669349e-03 1.19846426e-02 2.18364829e-03 4.00891341e-03\n",
      " 1.29024517e-02 3.44908834e-02 4.08677422e-02 3.74227576e-02\n",
      " 2.41638254e-02 6.08041324e-02 2.42151227e-02 6.80210367e-02\n",
      " 1.39312157e-02 3.53519432e-02 1.75124705e-02 2.42545903e-02\n",
      " 2.02170219e-02 3.33734043e-02 1.04938615e-02 2.48436015e-02\n",
      " 2.81189997e-02 1.33794015e-02 2.62066461e-02 2.35436186e-02\n",
      " 2.01494358e-02 2.08040718e-02 2.66199522e-02 1.97386537e-02\n",
      " 2.09116079e-02 1.22977663e-02 1.54442983e-02 1.34539008e-02\n",
      " 1.05142733e-02 1.10218022e-02 5.44331707e-02 1.94901973e-02\n",
      " 2.53648479e-02 3.60823236e-02 3.13969962e-02 1.76862516e-02\n",
      " 4.07569036e-02 4.39444231e-03 1.97624564e-02 4.75879526e-03\n",
      " 7.95936771e-03 3.29776704e-02 2.71551497e-02 3.47896223e-03\n",
      " 1.26695633e-02 1.01610813e-02 1.95221603e-02 8.53811484e-03\n",
      " 3.56169716e-02 2.81895231e-02 1.86394881e-02 1.38169993e-02\n",
      " 2.98935473e-02 3.04147881e-02 2.23286301e-02 3.56418686e-03\n",
      " 9.00710374e-03 3.67377885e-02 2.44105682e-02 2.03063115e-02\n",
      " 1.97530389e-02 1.02732908e-02 2.59521920e-02 7.24324510e-02\n",
      " 2.42652167e-02 1.26092769e-02 6.94588618e-03 1.63850673e-02\n",
      " 1.65631231e-02 2.40526274e-02 4.27115411e-02 2.27630474e-02\n",
      " 1.06605170e-02 6.14767009e-03 3.74397088e-04 7.06509920e-03\n",
      " 1.46297896e-02 1.49586126e-02 3.73559855e-02 1.51536847e-02\n",
      " 1.87273175e-02 3.10528744e-02 1.61039177e-02 1.21823819e-02\n",
      " 4.46277969e-02 3.15282308e-02 1.31548671e-02 4.21705544e-02\n",
      " 4.65912325e-03 3.02388091e-02 3.86527576e-03 1.47302300e-02\n",
      " 1.51825817e-02 1.88907590e-02 2.42823567e-02 1.06486939e-02\n",
      " 1.25273047e-02 1.23692006e-02 1.91242900e-02 1.18032796e-02\n",
      " 1.00650406e-02 2.46839300e-02 3.07632983e-02 3.07053979e-02\n",
      " 4.56442125e-02 3.00395619e-02 2.19497345e-02 3.76570038e-02\n",
      " 3.85491736e-02 2.51230411e-02 5.53870276e-02 3.23557556e-02\n",
      " 2.65307594e-02 1.56706683e-02 2.67573074e-02 1.06483800e-02\n",
      " 9.79242381e-03 2.25076973e-02 6.44564070e-03 1.52436011e-02\n",
      " 3.90687063e-02 3.11067533e-02 7.11586932e-03 9.69876349e-03\n",
      " 6.22175913e-03 6.12685969e-03 5.13586914e-03 1.28273517e-02\n",
      " 4.67451988e-03 1.79143529e-02 1.12516023e-02]\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "loss_array = loadtxt('loss_array.csv', delimiter=',')\n",
    "\n",
    "print(loss_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00164671 0.00134731 0.00257485 0.00590248 0.00991351\n",
      " 0.01545999 0.0236527  0.03141716 0.04170483 0.05595651 0.07231252\n",
      " 0.09203333 0.11401197 0.13784653 0.16237868 0.18558045 0.2080929\n",
      " 0.22877674 0.2487053  0.26628283 0.28250328 0.29761872 0.31210911\n",
      " 0.32608613 0.33912989 0.35092169 0.3613829  0.37139902 0.38081732\n",
      " 0.38954633 0.39777657 0.40578842 0.41374943 0.42106533 0.42782262\n",
      " 0.43428355 0.44031662 0.44620359 0.45168364 0.45681801 0.46188733\n",
      " 0.46662578 0.47113067 0.47560051 0.47973827 0.48383233 0.48763764\n",
      " 0.49148124 0.49537626 0.49902317 0.50247818 0.50588626 0.50928712\n",
      " 0.51247692 0.51562929 0.51860332 0.52148801 0.52406663 0.52652133\n",
      " 0.52916014 0.53154105 0.53386885 0.53614849 0.53830922 0.54058397\n",
      " 0.54278237 0.54496872 0.54713017 0.54925913 0.55125147 0.55304283\n",
      " 0.55488676 0.55669421 0.55847079 0.5602982  0.56208116 0.56375873\n",
      " 0.56534868 0.56700677 0.56848001 0.5700078  0.57153118 0.57309383\n",
      " 0.57454193 0.57591856 0.57724023 0.5786283  0.57999998 0.5813238\n",
      " 0.58262801 0.58389187 0.58507085 0.58621782 0.58730507 0.58845007\n",
      " 0.58951938 0.59053242 0.59159374 0.59264112 0.59359372 0.59458697\n",
      " 0.5955857  0.59656054 0.59747028 0.59834969 0.59924936 0.60016584\n",
      " 0.60109872 0.60193992 0.60289013 0.60376078 0.6046226  0.6054917\n",
      " 0.60634679 0.60714251 0.60788941 0.60865563 0.60942793 0.61010766\n",
      " 0.61077845 0.61155611 0.61228037 0.61296225 0.61360276 0.61426544\n",
      " 0.61494142 0.61563158 0.61631209 0.61694121 0.61760569 0.61821073\n",
      " 0.61886567 0.61952662 0.62016529 0.62075442 0.62130058 0.62184203\n",
      " 0.62234622 0.62287986 0.62338978 0.62396491 0.62447578 0.62496793\n",
      " 0.62548041 0.62597018 0.62641108 0.62685412 0.62731045 0.62778586\n",
      " 0.62827587 0.62877136 0.62925339 0.62974477 0.63020444 0.63061547\n",
      " 0.6310463  0.63146102 0.63189906 0.63229281 0.6327408  0.63315988\n",
      " 0.63355887 0.63398248 0.6343835  0.63479877 0.63521534 0.63564855\n",
      " 0.63605773 0.63647187 0.63684136 0.63720655 0.63759971 0.63799274\n",
      " 0.63837165 0.63876772 0.63914478 0.63947773 0.63982034 0.64019942\n",
      " 0.64056426 0.64092672 0.64131159 0.64163971 0.64198875 0.64236647\n",
      " 0.6427232  0.64305198 0.64336926 0.64373004 0.64407915 0.64436638\n",
      " 0.64470226 0.64500582 0.64531636 0.64560676 0.64586121 0.64615804\n",
      " 0.64644432 0.64674205 0.64705104 0.64736062 0.64763081 0.64790642\n",
      " 0.6481992  0.64851177 0.64876819 0.64907134 0.64940047 0.64971137\n",
      " 0.65000641 0.65029585 0.65058959 0.65085101 0.65111417 0.65135252\n",
      " 0.651604   0.6518358  0.65207309 0.65232259 0.65255618 0.65278965\n",
      " 0.65299404 0.65318644 0.65339053 0.65357012 0.65377605 0.65397745\n",
      " 0.65421861 0.65446872 0.65469909 0.6549086  0.65516287 0.65539825\n",
      " 0.65563798 0.65586865 0.65609354 0.65633553 0.65657169 0.65678144\n",
      " 0.65698749 0.65721053 0.65744972 0.65768445 0.65787971 0.65803975\n",
      " 0.65823019 0.65844518 0.65863001 0.65884346 0.65906721 0.65927786\n",
      " 0.659482   0.65968758 0.65987432 0.66008139 0.66029567 0.66049945\n",
      " 0.66069645 0.66087514 0.66105592 0.66123992 0.66144252 0.66163844\n",
      " 0.66182607 0.66202927 0.66221625 0.66240633 0.66260004 0.66276276\n",
      " 0.66296756 0.66316259 0.66332752 0.66348952 0.66364163 0.66377574\n",
      " 0.66390121 0.66404694 0.66420025 0.66435462 0.66452551 0.6647256\n",
      " 0.66489559 0.66503364 0.66520345 0.66536415 0.66554004 0.66569793\n",
      " 0.66585368 0.66598451 0.66612631 0.66624135 0.66636229 0.66650748\n",
      " 0.66667926 0.66679901 0.6669392  0.66711688 0.66728932 0.66744649\n",
      " 0.6676017  0.66776931 0.66792881 0.66808683 0.66822451 0.66838145\n",
      " 0.66853154 0.66869426 0.66886032 0.66899377 0.66912687 0.6692552\n",
      " 0.66940051 0.6695497  0.66970462 0.66983521 0.66997069 0.67010862\n",
      " 0.67025793 0.6704157  0.67057341 0.67072171 0.67086959 0.67098731\n",
      " 0.67109412 0.67120486 0.67130119 0.67142254 0.67153537 0.67164755\n",
      " 0.67175996 0.67188662 0.67200667 0.67213589 0.67225802 0.67238933\n",
      " 0.67253006 0.67264062 0.67275184 0.67285973 0.67297763 0.67307937\n",
      " 0.67317748 0.67328948 0.67341518 0.67355013 0.67367089 0.6737957\n",
      " 0.67389995 0.67400581 0.67412341 0.67424679 0.67435241 0.67448127\n",
      " 0.67458099 0.67469954 0.67481238 0.67492253 0.67501777 0.67512506\n",
      " 0.67525172 0.67534822 0.67543417 0.67554945 0.67566699 0.67579329\n",
      " 0.67591232 0.67601728 0.67611879 0.67622948 0.67633998 0.67645478\n",
      " 0.67655683 0.67666721 0.676781   0.67687613 0.67696482 0.67703277\n",
      " 0.6771099  0.6772182  0.67731059 0.67740482 0.67749196 0.67758834\n",
      " 0.67770922 0.67783654 0.67795461 0.67807281 0.67818195 0.67827857\n",
      " 0.67836314 0.67846268 0.67857158 0.67865211 0.67872959 0.67881501\n",
      " 0.67889959 0.67898303 0.679057   0.67913622 0.67922664 0.67929685\n",
      " 0.67936069 0.67943168 0.67949712 0.67958039 0.67965919 0.67974013\n",
      " 0.6798299  0.67991263 0.68000704 0.68009436 0.68017113 0.68024713\n",
      " 0.68033582 0.6804226  0.68051982 0.68062699 0.68070924 0.68078929\n",
      " 0.68087184 0.68095332 0.68101978 0.68109733 0.68119037 0.68128091\n",
      " 0.68136394 0.68145084 0.68155336 0.68164289 0.68173337 0.68182105\n",
      " 0.68190789 0.68200618 0.68209499 0.68216825 0.68225008 0.6823377\n",
      " 0.68240923 0.68247664 0.68255097 0.68263167 0.68269336 0.68277782\n",
      " 0.68285382 0.68293482 0.68300736 0.68309438 0.68318069 0.68325359\n",
      " 0.68332809 0.68339837 0.68346792 0.68354684 0.68361843 0.68369365\n",
      " 0.68376398 0.68381792 0.68387586 0.68395054 0.68404216 0.68413436\n",
      " 0.68422937 0.6843366  0.68441886 0.68449622 0.68456781 0.6846391\n",
      " 0.68472159 0.68479764 0.68485427 0.68491602 0.68497819 0.68504548\n",
      " 0.68511057 0.68516529 0.68523365 0.68530548 0.68537509 0.68545353\n",
      " 0.68553382 0.6856066  0.68568814 0.68577051 0.68584794 0.68591022\n",
      " 0.68599194 0.68606478 0.68614125 0.68621284 0.68628687 0.68635392\n",
      " 0.68641394 0.68649381 0.68656212 0.68663079 0.68669492 0.68674827\n",
      " 0.68681341 0.6868903  0.6869579  0.68702018 0.68708754 0.6871618\n",
      " 0.68723488 0.68730944 0.68739378 0.68746477 0.68753368 0.68759882\n",
      " 0.68766987 0.68774158 0.68781263 0.68788815 0.68794584 0.68801117\n",
      " 0.68807274 0.68812919 0.6882062  0.68828583]\n"
     ]
    }
   ],
   "source": [
    "valid_acc_array = loadtxt('valid_acc_array.csv', delimiter=',')\n",
    "\n",
    "print(valid_acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00159681 0.00304391 0.00744761 0.01137725 0.01818862 0.02763045\n",
      " 0.03439371 0.04807052 0.06390718 0.08079749 0.10249501 0.12524183\n",
      " 0.15004277 0.17376247 0.19700599 0.21845721 0.23872255 0.25784746\n",
      " 0.27430388 0.29014114 0.30480403 0.3191812  0.33291543 0.34546107\n",
      " 0.35617226 0.3663229  0.37636334 0.38527256 0.3937026  0.40174812\n",
      " 0.40994573 0.41751042 0.42452008 0.43119332 0.4372713  0.44323921\n",
      " 0.44910181 0.4542492  0.45940495 0.4643749  0.46888366 0.4735204\n",
      " 0.47773203 0.48179972 0.48585328 0.48956874 0.49345684 0.49730539\n",
      " 0.50074553 0.50422388 0.50771534 0.5108971  0.51411068 0.51715022\n",
      " 0.52011603 0.52286482 0.52527618 0.52786463 0.5304541  0.53268874\n",
      " 0.53508306 0.53715903 0.53953969 0.54169506 0.54394168 0.54604298\n",
      " 0.54822344 0.55030376 0.55218351 0.55394912 0.55586535 0.55760604\n",
      " 0.55939066 0.56119758 0.56297272 0.56460261 0.5662387  0.56773287\n",
      " 0.56926459 0.57078987 0.57232732 0.57386011 0.57527268 0.57661325\n",
      " 0.57796097 0.57932752 0.58069885 0.58199894 0.5832901  0.58452493\n",
      " 0.58566451 0.58677322 0.58792204 0.58900726 0.59004182 0.59104264\n",
      " 0.59214377 0.59313947 0.59408236 0.59511769 0.59608138 0.59710044\n",
      " 0.5978927  0.59884518 0.59971613 0.60066599 0.60153168 0.60241169\n",
      " 0.60337782 0.60422534 0.6050778  0.60594958 0.60679299 0.60752666\n",
      " 0.60826451 0.60902554 0.60978508 0.61044133 0.61117518 0.61193401\n",
      " 0.61263496 0.61331242 0.61393183 0.61460239 0.61530632 0.61600029\n",
      " 0.61663431 0.61727476 0.61790878 0.61854118 0.61920363 0.61985278\n",
      " 0.62047994 0.62104458 0.62155026 0.62209666 0.62263191 0.62311423\n",
      " 0.62367195 0.62423873 0.62473541 0.6252104  0.6257329  0.62617487\n",
      " 0.62662929 0.62707442 0.62754893 0.62804425 0.62852794 0.62901813\n",
      " 0.62952054 0.6299724  0.63042033 0.63082868 0.63124138 0.63169456\n",
      " 0.63210416 0.63251513 0.63294071 0.63336092 0.63376027 0.63417768\n",
      " 0.63459998 0.63499546 0.63541955 0.63585287 0.63627118 0.63665009\n",
      " 0.63702536 0.63739276 0.63778549 0.63820308 0.63855994 0.6389752\n",
      " 0.63928622 0.63964361 0.64000624 0.64040244 0.64073521 0.64112794\n",
      " 0.64147449 0.64181066 0.64217329 0.64253926 0.64288682 0.64322585\n",
      " 0.6435318  0.64391136 0.64420658 0.64450419 0.64486575 0.64514673\n",
      " 0.64547038 0.64572698 0.64601004 0.64630991 0.64659166 0.64690745\n",
      " 0.64721632 0.64750201 0.64777374 0.64805537 0.64837676 0.64863884\n",
      " 0.64890993 0.64923269 0.64955521 0.64986676 0.65016466 0.65045905\n",
      " 0.65072381 0.65099239 0.65125078 0.65147543 0.65172571 0.65194815\n",
      " 0.65218717 0.65243214 0.65267557 0.65289712 0.65311134 0.65329206\n",
      " 0.65347785 0.65368861 0.65387696 0.65409267 0.65436363 0.65459365\n",
      " 0.65479887 0.65505093 0.65528536 0.65552092 0.65575707 0.65598422\n",
      " 0.65621763 0.65645546 0.6566931  0.65688747 0.6570977  0.65733844\n",
      " 0.65756053 0.65779859 0.65796787 0.65814185 0.65834248 0.65853715\n",
      " 0.65874845 0.65895617 0.65918684 0.65937448 0.65958738 0.65977728\n",
      " 0.65998101 0.66018903 0.66039717 0.66060662 0.66079587 0.66097093\n",
      " 0.66114634 0.66133994 0.66155779 0.66172671 0.66194034 0.6621325\n",
      " 0.6623109  0.66250533 0.66268939 0.66286755 0.66307276 0.66325653\n",
      " 0.6634202  0.66357064 0.66371346 0.66384321 0.66396499 0.66413021\n",
      " 0.66427594 0.66443723 0.66462469 0.66481346 0.66496319 0.66511023\n",
      " 0.66528106 0.66544807 0.66562015 0.66578066 0.66591871 0.66605937\n",
      " 0.66618317 0.66630089 0.66642398 0.6665892  0.66674459 0.66686493\n",
      " 0.66702187 0.66720802 0.66736931 0.6675185  0.66768116 0.66784871\n",
      " 0.66800272 0.66815823 0.66830778 0.66844654 0.66861671 0.66878814\n",
      " 0.66893375 0.66905415 0.66919208 0.66933209 0.66947836 0.66962463\n",
      " 0.66977048 0.66991305 0.67003572 0.67018265 0.67033857 0.67049068\n",
      " 0.6706484  0.67079437 0.67093343 0.6710304  0.67116094 0.6712501\n",
      " 0.67136997 0.67148316 0.67159748 0.6717093  0.67182589 0.67195535\n",
      " 0.67207003 0.67220873 0.67232424 0.6724667  0.6725865  0.67271316\n",
      " 0.67280501 0.67292011 0.67302877 0.67314172 0.67322809 0.6733498\n",
      " 0.67347991 0.67361104 0.67373401 0.67384768 0.67394906 0.67405331\n",
      " 0.67418563 0.6743018  0.67442286 0.67452967 0.67463887 0.67476088\n",
      " 0.67487049 0.67497063 0.67506438 0.6751914  0.67530066 0.67538649\n",
      " 0.6754896  0.67560995 0.6757341  0.67585188 0.6759755  0.67606503\n",
      " 0.67617565 0.67627794 0.67639989 0.67650789 0.67660886 0.67673141\n",
      " 0.67683363 0.67692816 0.67699867 0.67707556 0.6771639  0.67727512\n",
      " 0.67736566 0.67744356 0.6775257  0.67763913 0.67777455 0.67790031\n",
      " 0.67801458 0.67813134 0.6782313  0.67831999 0.67841893 0.67851663\n",
      " 0.67862105 0.67869073 0.67876267 0.67885733 0.67894626 0.67903364\n",
      " 0.67909271 0.67918074 0.6792717  0.67932636 0.67939603 0.67946279\n",
      " 0.6795314  0.67961597 0.67969751 0.6797772  0.67987007 0.67995876\n",
      " 0.68005222 0.68013388 0.68019849 0.68029606 0.68037874 0.68046969\n",
      " 0.6805706  0.6806739  0.68075061 0.68083084 0.68091071 0.68099195\n",
      " 0.68105471 0.68114907 0.68123484 0.68132615 0.681409   0.68150687\n",
      " 0.68160224 0.68169433 0.6817745  0.68186992 0.68195552 0.68205804\n",
      " 0.68214047 0.68221349 0.68229586 0.68237197 0.68245494 0.68252051\n",
      " 0.68259764 0.68267006 0.6827333  0.68282026 0.68289065 0.68297082\n",
      " 0.68304694 0.68314141 0.68322015 0.68329555 0.68337262 0.683433\n",
      " 0.68350708 0.68358117 0.68366057 0.68373728 0.6837939  0.68384546\n",
      " 0.68390852 0.68399864 0.68408519 0.68418014 0.68428081 0.68438393\n",
      " 0.68445826 0.68453676 0.68460619 0.68468183 0.68476027 0.68483174\n",
      " 0.6848895  0.68494952 0.68501186 0.68508154 0.68514776 0.68518782\n",
      " 0.6852693  0.68533498 0.6854108  0.68549246 0.68557197 0.68564743\n",
      " 0.68572998 0.68581039 0.68588144 0.68594944 0.68602669 0.68610245\n",
      " 0.68618459 0.6862517  0.68632197 0.68638945 0.68645513 0.68653148\n",
      " 0.68659025 0.6866703  0.68672794 0.68678451 0.68685192 0.68692267\n",
      " 0.68699193 0.68705851 0.68712485 0.68719423 0.68727428 0.68734956\n",
      " 0.68742782 0.68750519 0.68756717 0.68763399 0.68771249 0.68778229\n",
      " 0.68784648 0.68792272 0.68798053 0.68804139 0.68810487 0.6881696\n",
      " 0.68824589 0.68832105]\n"
     ]
    }
   ],
   "source": [
    "pre_array = loadtxt('pre_array.csv', delimiter=',')\n",
    "\n",
    "print(pre_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pre_array)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('number of iterations/20')\n",
    "plt.legend(['test accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
